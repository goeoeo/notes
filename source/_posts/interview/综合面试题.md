---
title: golang面试题
categories: 
- interview
tags:
- golang
---

# rpc微服务框架
## 微服务之间如何进行通信？
* 单体项目时：一次服务调用发生在同一台机器上的同一个进程内部，也就是说调用发生在本机内部，因此也被叫作本地方法调用。
* 微服务项目时：服务提供者和服务消费者运行在两台不同物理机上的不同进程内，它们之间的调用相比于本地方法调用，可称之为远程方法调用，简称 RPC

## RPC了解多少？都有哪些？
受限语言的开源 RPC 框架   
* Dubbo (java)
* Motan (java)
* Tars (c++)
* Spring Cloud Feigh (java)

跨语言平台的开源 RPC 框架  
* GRPC：Google 2015 年开源，支持多种语言
* Thrift：最初Facebook 开发的内部框架，2007 年贡献给了 Apache 基金，成为 Apache 开源项目之一，支持多种语言。

## RPC包含哪些部分？
* 客户端和服务端建立网络连接模块( server模块、client模块 )
* 服务端处理请求模块
* 协议模块
* 序列化和反序列模块

## 设计一个RPC会考虑哪些问题?
* 客户端和服务端如何建立网络连接？
* 服务端如何处理请求？
* 数据传输采用什么协议？
* 数据该如何序列化和反序列化？

## 服务端如何处理请求？有哪些方式？
服务端接收到客户端的请求后，常见的处理方式有三种，分别是BIO、NIO和AIO。  
* **同步阻塞方式（BIO）** 客户端发一次请求，服务端生成一个对应线程去处理。当客户端同时发起的请求很多时，服务端需要创建多个线程去处理每一个请求，当达到了系统最大的线程数时，新来的请求就无法处理了。
* **同步非阻塞方式 (NIO)**  客户端发一次请求，服务端并不是每次都创建一个新线程来处理，而是通过 I/O 多路复用技术进行处理。就是把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求。这种方式的优势是开销小，不用为每个请求创建一个线程，可以节省系统开销。
* **异步非阻塞方式（AIO）**  客户端发起一个 I/O 操作然后立即返回，等 I/O 操作真正完成以后，客户端会得到 I/O 操作完成的通知，此时客户端只需要对数据进行处理就好了，不需要进行实际的 I/O 读写操作，因为真正的 I/O 读取或者写入操作已经由内核完成了。这种方式的优势是客户端无需等待，不存在阻塞等待问题。

> BIO 适用于连接数比较小的业务场景，这样的话不至于系统中没有可用线程去处理请求。这种方式写的程序也比较简单直观，易于理解。
> NIO 适用于连接数比较多并且请求消耗比较轻的业务场景，比如聊天服务器。这种方式相比 BIO，相对来说编程比较复杂。
> AIO 适用于连接数比较多而且请求消耗比较重的业务场景，比如涉及 I/O 操作的相册服务器。这种方式相比另外两种，编程难度最大，程序也不易于理解。 【来自网络】

### IO多路复用
多个的进程的IO可以注册到一个复用器（select）上，然后用一个进程调用该select， select会监听所有注册进来的IO；  
如果select没有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞；而当任一IO在内核缓冲区中有可数据时，select调用就会返回；  
而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据。  
可以看到，多个进程注册IO后，只有另一个select调用进程被阻塞。

IO多路复用实现有三种方案：select、poll、epoll   
特点：
* 专一进程解决多个进程IO的阻塞问题，性能好
* 实现、开发应用难度较大；
* 适用高并发服务应用开发：一个进程（线程）响应多个请求；


### select
select 的fd_set通过bitmap 1024位的方式存储fd  
bitmap从用户态拷贝到内核态，由内核态来判断，没有数据变化，select会阻塞，有变化，bitmap的fd会被置位

缺点：
1. 1024的大小限制
2. fdset不可重用
3. rset(bitmap) 用户态到内核态的开销
4. 复杂度为O(n)

### poll
poll将要监听的对象存到数组中，且数组中的元素是结构体
```
struct pollfd
{
    int fd;
    short events;//事件
    short revents;//有变化被置位，什么事件，置为什么事件，最后要将revents重新置为0
}

```
解决了select中 的两个问题
1. 1024的大小限制
2. fdset不可重用

### epoll
epoll的接口非常简单，一共就三个函数
* epoll_create：创建一个epoll句柄
* epoll_ctl：向 epoll 对象中添加/修改/删除要管理的连接
* epoll_wait：等待其管理的连接上的 IO 事件

### epoll的边缘触发与水平触发
**水平触发(LT)**

关注点是数据是否有无，只要读缓冲区不为空，写缓冲区不满，那么epoll_wait就会一直返回就绪，水平触发是epoll的默认工作方式。

**边缘触发(ET)**

关注点是变化，只要缓冲区的数据有变化，epoll_wait就会返回就绪。
这里的数据变化并不单纯指缓冲区从有数据变为没有数据，或者从没有数据变为有数据，还包括了数据变多或者变少。即当buffer长度有变化时，就会触发。
假设epoll被设置为了边缘触发，当客户端写入了100个字符，由于缓冲区从0变为了100，于是服务端epoll_wait触发一次就绪，服务端读取了2个字节后不再读取。这个时候再去调用epoll_wait会发现不会就绪，只有当客户端再次写入数据后，才会触发就绪。
这就导致如果使用ET模式，那就必须保证要「一次性把数据读取&写入完」，否则会导致数据长期无法读取/写入

### epoll 为什么比select、poll更高效？
* epoll 为什么比select、poll更高效？
* epoll 将文件描述符添加和检测分离，减少了文件描述符拷贝的消耗
  select&poll 调用时会将全部监听的 fd 从用户态空间拷贝至内核态空间并线性扫描一遍找出就绪的 fd 再返回到用户态。下次需要监听时，又需要把之前已经传递过的文件描述符再读传递进去，增加了拷贝文件的无效消耗，当文件描述很多时，性能瓶颈更加明显。
  而epoll只需要使用epoll_ctl添加一次，后续的检查使用epoll_wait，减少了文件拷贝的消耗。

### 总结
select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，
epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O
的实现会负责把数据从内核拷贝到用户空间。

select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间
也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是
select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列
上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。
  




<!--more-->

# mq底层数仓
# runtime包里面的方法
Go 语言的 goroutine 是由 运行时（runtime）调度和管理的  

Go 语言的 runtime 类似 Java 和 .NET 语言所用到的虚拟机，它负责管理包括内存分配、垃圾回收（第 10.8 节）、栈处理、goroutine、channel、切片（slice）、map 和反射（reflection）等等。

1. Gosched()：让当前线程让出 cpu 以让其它线程运行，它不会挂起当前线程，因此当前线程未来会继续执行。
2. NumCPU()：返回当前系统的 CPU 核数量。
3. GOMAXPROCS()：设置最大的可同时使用的 CPU 核数。 通过runtime.GOMAXPROCS函数，应用程序可以设置运行时系统中的 P 最大数量。注意，如果在运行期间设置该值的话，会引起“Stop the World”。所以，应在应用程序最早期调用，并且最好是在运行Go程序之前设置好操作程序的环境变量GOMAXPROCS，而不是在程序中调用runtime.GOMAXPROCS函数。
4. Goexit()：退出当前 goroutine（但是defer语句会照常执行）。
5. NumGoroutine：返回正在执行和排队的任务总数。
6. runtime.NumGoroutine函数在被调用后，会返回系统中的处于特定状态的 Goroutine 的数量。这里的特定状态是指Grunnable\Gruning\Gsyscall\Gwaition。处于这些状态的Groutine即被看做是活跃的或者说正在被调度。 注意：垃圾回收所在Groutine的状态也处于这个范围内的话，也会被纳入该计数器。
7. GOOS：查看目标操作系统。很多时候，我们会根据平台的不同实现不同的操作，就可以用GOOS来查看自己所在的操作系统。
8. runtime.GC：会让运行时系统进行一次强制性的垃圾收集。 强制的垃圾回收：不管怎样，都要进行的垃圾回收。非强制的垃圾回收：只会在一定条件下进行的垃圾回收（即运行时，系统自上次垃圾回收之后新申请的堆内存的单元（也成为单元增量）达到指定的数值）。
9. GOROOT() ：获取 goroot 目录。
10. runtime.LockOSThread 和 runtime.UnlockOSThread 函数：前者调用会使调用他的 Goroutine 与当前运行它的M锁定到一起，后者调用会解除这样的锁定。

# redis过期策略和内存淘汰策略
Redis的过期策略和内存淘汰策略是处理内存使用和键过期的重要机制。  
过期策略主要有三种：

1. 定时过期：为每个设置过期时间的键创建一个定时器，当到达过期时间时立即清除该键。这种策略可以立即清除过期的数据，对内存友好，但会占用大量CPU资源，可能影响缓存的响应时间和吞吐量。
2. 惰性过期：只有在访问一个键时，才会判断该键是否已过期，如果过期则清除。这种策略可以最大化地节省CPU资源，但对内存不太友好。在极端情况下，可能会出现大量过期键没有被再次访问，从而不会被清除，占用大量内存。
3. 定期过期：每隔一定的时间，扫描一定数量的键，并清除其中已过期的键。这种策略是前两者的折中方案，通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
内存淘汰策略在Redis中也很重要，当内存使用超过配置的时候，Redis会采用以下策略之一：

1. noeviction：当内存使用超过配置的时候返回错误，不删除任何键（默认策略）。
2. allkeys-lru：通过LRU（最近最少使用）算法删除最久没有使用的键。
3. volatile-lru：从设置了过期时间的键集合中删除最久没有使用的键。
4. allkeys-random：从所有键中随机删除。
5. volatile-random：从过期键集合中随机删除。
6. volatile-ttl：从配置了过期时间的键中删除过期时间最近的键。
7. volatile-lfu：从所有配置了过期时间的键中删除使用频率最少的键。
8. allkeys-lfu：从所有键中删除使用频率最少的键。
这些策略可以帮助Redis在内存压力较大时，根据一定的规则自动删除一些键，从而释放内存空间。选择合适的策略需要根据具体的应用场景和需求来决定。

# sql索引优化问题
SQL索引优化是数据库性能调优的关键部分。正确的索引策略可以显著提高查询性能，而错误的索引可能会导致性能下降，甚至在某些情况下导致数据库锁争用和其他问题。  

## 何时应该创建索引？
* 当经常根据某个列或列的组合进行查询时。
* 当某个列在WHERE子句、JOIN操作或ORDER BY子句中频繁使用时。
* 当表中的数据量很大，且查询需要扫描大量行时。

## 何时应该避免创建索引？
* 当表的行数很少时。
* 当某个列的值几乎相同或非常稀疏时（即大多数行的该列值都是NULL）。
* 当需要频繁更新的列，因为索引维护会带来性能开销。

## 如何选择索引列？
* 选择经常出现在WHERE子句中的列。
* 选择在ORDER BY和GROUP BY子句中使用的列。
* 选择作为连接条件的列，特别是在JOIN操作中。
* 考虑使用复合索引来覆盖多个查询条件。

## 如何维护索引？
* 定期检查索引的使用情况，并根据实际情况进行调整。
* 使用数据库管理系统的工具和查询来查看索引的效率，例如EXPLAIN计划。
* 定期重建或重新组织索引以消除碎片化，保持其性能。

## mysql索引种类

| 从逻辑功能划分 | 从物理实现划分 | 从作用字段划分 |
|---------|---------|---------|
| 普通索引、唯一索引、主键索引、全文索引        |  聚簇索引、非聚簇索引       |     单列索引、联合索引    |



# 一个update语句的执行过程
1. 解析（Parsing）：

客户端（如 SQL 客户端工具）将 UPDATE 语句发送给 MySQL 服务器。
服务器首先解析 SQL 语句，检查语法是否正确，并确定要执行的操作。
2. 预处理（Preprocessing）：

MySQL 检查语句中涉及的表和列是否存在，以及用户是否有足够的权限执行此操作。
如果语句中使用了任何存储过程或函数，它们在这个阶段也会被处理。
3. 优化（Optimization）：

MySQL 优化器（Optimizer）确定执行该 UPDATE 语句的最佳方法。
优化器可能会考虑多种执行计划，并选择其中一个认为是最有效的。
例如，如果 UPDATE 语句涉及多个索引，优化器可能会选择使用哪个索引来最快地找到需要更新的行。
4. 执行（Execution）：

一旦确定了执行计划，MySQL 开始执行 UPDATE 语句。
它首先定位到需要更新的行，然后根据 SET 子句中的值来更新这些行。
在这个过程中，MySQL 可能会锁定涉及的行或表，以防止其他事务同时修改这些数据。
5. 写回（Write-back）：

如果更新操作导致了数据页的变化，MySQL 会将这些变化写回到磁盘上。
这个过程可能涉及日志记录（例如，在 InnoDB 存储引擎中，可能会写入重做日志和/或撤销日志）。
6. 提交（Commit）：

如果该操作是在事务中执行的，那么在执行完 UPDATE 语句后，事务需要被提交。
提交操作会确保所有之前的更改都被永久保存，并且对其他事务可见。
如果在提交过程中出现错误，MySQL 可能会执行回滚操作，撤销之前所做的更改。


# go的profile工具？
## 有哪几种采样方式
* runtime/pprof：采集程序（非 Server）的指定区块的运行数据进行分析。
* net/http/pprof：基于 HTTP Server 运行，并且可以采集运行时数据进行分析。
* go test：通过运行测试用例，并指定所需标识来进行采集。
* gops: 针对非HTTP Server的其它Server 比如GRPC Server 持续采集


## 支持什么使用模式
* Report generation：报告生成。
* Interactive terminal use：交互式终端使用。
* Web interface：Web 界面。
* graphviz 图形化采集结果


## 可以做什么
* CPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期时花费时间的位置。
* Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。
* Block Profiling：阻塞分析，记录 Goroutine 阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用 runtime.SetBlockProfileRate 进行设置。
* Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用 runtime.SetMutexProfileFraction 进行设置。
* Goroutine Profiling： Goroutine 分析，可以对当前应用程序正在运行的 Goroutine 进行堆栈跟踪和分析。这项功能在实际排查中会经常用到，
  因为很多问题出现时的表象就是 Goroutine 暴增，而这时候我们要做的事情之一就是查看应用程序中的 Goroutine 正在做什么事情，因为什么阻塞了，然后再进行下一步。



# http和tcp有什么区别
1. 性质：HTTP是一个简单的请求-响应协议，主要基于文本进行传输，通常运行在TCP之上。而TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，主要负责数据的可靠传输。
2. 连接：TCP连接是不同但互连的计算机通信网络的主计算机中的成对进程之间的连接，它提供可靠的通信服务。而HTTP通常运行在TCP之上，指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。
3. 功能：当应用层向TCP层发送用于网间传输的、用8位字节表示的数据流时，TCP会将数据流分割成适当长度的报文段，最大传输段大小（MSS）通常受该计算机连接的网络的数据链路层的最大传送单元（MTU）限制。而HTTP协议是基于请求/响应范式的，用于传输超文本或其他内容。
4. 位置：HTTP协议对应于应用层，而TCP协议对应于传输层。从本质上来说，HTTP协议是建立在TCP协议基础之上的。



# 用netstat看tcp连接的时候有关注过time_wait和close_wait吗？
**time_wait**  
time_wait状态表示一个TCP连接在主动关闭之后等待一段时间，以确保最后一个网络分组（可能是之前连接中的最后一个ACK或其他分组）能够安全地到达对方。这是TCP协议设计中的一个重要部分，以避免因延迟的分组导致的新连接与旧连接之间的混淆。在time_wait状态下，连接不会立即关闭，而是会等待一个特定的时间（通常是2倍的MSL，Maximum Segment Lifetime，最大报文段生存时间），以确保所有的分组都已到达对方。

**close_wait**  
close_wait状态表示远程关闭了TCP连接，但本地应用程序还没有关闭套接字。换句话说，这是一个半开状态，其中一方已经决定结束连接，但另一方还没有响应。这通常是由于本地应用程序未能正确处理远程关闭的连接，或者由于应用程序的bug导致的。如果发现有大量的连接处于close_wait状态，这可能是一个性能问题或应用程序错误的指示，需要进一步调查。

# 如何处理
* 对于time_wait，通常不需要手动干预，因为它是TCP协议的正常部分。但是，如果服务器上有大量的time_wait连接，可能会耗尽可用端口，这时可以考虑调整TCP参数，如tcp_fin_timeout，或者使用SO_REUSEADDR套接字选项。
* 对于close_wait，应该检查应用程序的代码和逻辑，确保在接收到远程关闭连接的通知时，本地也正确地关闭了连接。此外，定期清理和监控处于close_wait状态的连接也是很有帮助的。

>  netstat -natp 查看网络连接情况

# fork的底层实现方式
fork() 是一个 Unix/Linux 系统调用，它创建一个与当前进程几乎完全相同的子进程。新创建的子进程（子进程）获得与父进程（调用 fork() 的进程）几乎完全相同的环境：相同的程序，相同的开放文件和环境变量等。子进程和父进程之间的主要区别在于它们的 PID（进程 ID）和 PPID（父进程 ID），以及某些状态和资源使用情况（如未处理的信号和文件锁）。

fork() 的底层实现方式主要依赖于操作系统内核，特别是其进程管理和内存管理部分。以下是一个简化的 fork() 实现概述：  
1. 复制进程描述符
* 当一个进程调用 fork() 时，内核首先为新的子进程创建一个新的进程描述符（也称为任务结构或进程控制块）。
* 这个新的进程描述符是父进程描述符的一个副本，但大多数字段（如 PID 和 PPID）都需要修改。

2. 复制或共享内存
* 写时复制 (Copy-on-Write, CoW) 这是大多数现代 Unix/Linux 系统使用的策略。在 fork() 时，子进程并不立即获得父进程的物理内存页的副本。相反，它们共享相同的物理内存页，但每个页面都有一个额外的引用计数器。当任何一个进程尝试修改一个页面时，内核会为该页面创建一个新的副本，并更新相应的引用计数器。这样可以节省内存，因为许多进程在创建后很快就执行 exec() 系列调用，替换了它们的内存内容。
* 完全复制：在某些情况下，或者在某些操作系统版本中，子进程会立即获得父进程内存空间的完整副本。这会增加 fork() 的开销，但确保子进程和父进程在 fork() 后有完全独立的内存空间。

3. 复制其他资源
* 除了内存外，还需要复制其他进程资源，如打开的文件描述符、信号处理程序、信号屏蔽字、账户信息、进程调度信息等。
* 在许多情况下，子进程和父进程会共享某些资源，如文件描述符（使用写时复制策略）。

4. 设置子进程的上下文
* 子进程需要有自己的上下文，包括其自己的寄存器状态、栈和程序计数器。这通常是通过复制父进程的上下文并稍作修改来实现的。
* 在某些情况下，子进程可能会立即执行一个新的程序（通过 exec() 系列调用），因此不需要保留父进程的上下文。

5. 返回
fork() 在父进程中返回子进程的 PID，在子进程中返回 0。这样，父进程和子进程就可以根据它们的返回值来区分自己的身份，并执行相应的操作。


# go语言什么时候垃圾回收，写代码的时候如何减少小对象分配
## go垃圾回收GC触发条件
1. 超过内存大小阈值
2. 达到定时时间

阈值是由一个gcpercent的变量控制的,当新分配的内存占已在使用中的内存的比例超过gcprecent时就会触发。比如一次回收完毕后，内存的使用量为5M，那么下次回收的时机则是内存分配达到10M的时候。也就是说，并不是内存分配越多，垃圾回收频率越高。 如果一直达不到内存大小的阈值呢？这个时候GC就会被定时时间触发，比如一直达不到10M，那就定时（默认2min触发一次）触发一次GC保证资源的回收。

## 减少小对象分配
1. 使用对象池
2. 结构体复用 如果你的程序中频繁地创建和销毁具有相同字段的结构体对象，可以考虑使用切片（slice）或映射（map）来存储这些对象，并在需要时重用它们。通过避免频繁地分配和释放内存，可以减少垃圾回收的压力。
3. 使用更大的数据结构 如果频繁分配的小对象可以组合成更大的数据结构，那么使用这些更大的数据结构可能会更有效。例如，使用切片（slice）代替单独的对象，或者使用映射（map）代替独立的键值对。



## redis的存储结构？
1. 字符串
2. 哈希表
3. 列表
4. 集合
5. 有序集合
6. 地理位置（Geo）
7. 基数统计（HyperLogLog）
8. 位图（Bitmaps）

# 实现map的方法除了哈希还有哪些？
哈希表，散列表（Scatter Table）：散列表是另一种用于实现映射的数据结构，它通过哈希函数将键映射到散列表中的槽位。每个槽位存储一个值或一个指向值的指针。当发生哈希冲突时，可以使用链地址法、开放地址法等策略进行处理。


1. 二叉搜索树（Binary Search Tree）：二叉搜索树是一种常用的数据结构，它可以用来实现映射。在二叉搜索树中，每个节点都包含一个键和一个值，树的左子树包含所有键小于当前节点键的节点，右子树包含所有键大于当前节点键的节点。通过遍历二叉搜索树，我们可以找到特定的键并返回对应的值。
2. 平衡二叉搜索树（Balanced Binary Search Tree）：平衡二叉搜索树是二叉搜索树的改进版本，它通过维护树的平衡性来确保查找、插入和删除操作的效率。常见的平衡二叉搜索树有AVL树、红黑树等。
3. B树（B-Tree）：B树是一种自平衡的树，主要用于维护排序数据的有序性。B树的阶（order）定义了每个节点允许的最大子节点数目。B树在数据库和文件系统中广泛应用，也可以用来实现映射。
4. B+树（B+-Tree）：B+树是B树的变种，它在B树的基础上进行了优化。B+树的叶子节点之间通过指针相连，形成了一个有序链表，这使得范围查询和顺序访问变得更加高效。B+树在数据库索引中广泛使用。
5. Trie树（前缀树）：Trie树是一种用于存储字符串集合的树形数据结构。在Trie树中，每个节点表示一个字符，从根节点到某个节点的路径表示一个字符串。Trie树非常适合用于实现基于字符串键的映射。

# 怎么理解redis的事务
## 语法
* multi 开起事务
* exec 执行事务
* discard 回滚事务

redis的事务功能很弱，在事务回滚机制上，Redis只能对基本的语法错误进行判断   
1. 语法命令错误，会回滚
2. 运行时错误，不能回滚


## 原理
事务是Redis实现在服务端的行为，用户执行MULTI时，服务器会将对应这个用户的客户端对象设置为一种特殊状态，在这个状态下后续用户执行的查询命令不会被
真的执行，而是被服务器缓存起来，知道用户执行Exec命令为止，服务器会将这个用户对应的客户端对象中缓存的命令按提交的顺序依次执行

# redis的setnx底层怎么实现的？
1. **检查键是否存在**：在Redis中，所有的键值对都保存在哈希表中。当用户发起SETNX命令时，Redis会先在哈希表中查询键是否存在。为了避免哈希表中存在大量的冲突，Redis会在哈希表的每个桶上都放置一条链表，所以在检查键是否存在的时候，只需要扫描一条链表即可。
2. **插入键值对**：如果检查发现该键并不存在，那么Redis会将该键值对插入到哈希表中，并返回成功插入的信息，否则返回插入失败的信息。在插入键值对的过程中，Redis会先分配一个新的哈希表节点，然后将键值对添加到哈希表节点中，最后将哈希表节点插入到哈希表的对应桶上的链表中。

由于Redis采用的是单线程机制，所以在检查和插入的过程中，所有的操作都是原子性的，即不可分割的。这种机制保证了SETNX命令的原子性，使得多个客户端并发执行SETNX命令时，只有一个客户端能够成功设置键的值。



# go的gc原理了解吗？
Go语言的垃圾回收器（GC）是一种自动内存管理机制，用于回收在程序运行过程中不再使用的内存。Go语言的垃圾回收器基于标记-清除（mark-sweep）算法，并采用了并发执行和调优参数等特性。

1. 标记-清除算法: 在标记-清除算法中，垃圾回收器会找出所有还在使用的内存块，并将所有未使用的内存块标记为可回收的。接着，垃圾回收器会扫描整个内存空间，将所有被标记的内存块清除掉。这个过程称为垃圾回收。
2. 三色标记法: Go语言的垃圾回收器还采用了三色标记法来提高效率。三色标记法将对象分为三种状态：白色、灰色和黑色。白色表示该对象未被标记过，灰色表示该对象已被标记，但其子对象可能还未被标记，黑色表示该对象及其子对象都已被标记。通过不断将灰色对象标记为黑色，并将黑色对象的子对象标记为灰色，最终将所有可达对象标记为黑色，然后清除所有白色对象，完成垃圾回收。
3. 写屏障技术: 此外，Go语言的垃圾回收器还采用了写屏障技术来避免在标记过程中产生新的引用关系，从而保证了标记的准确性。写屏障技术包括插入写屏障和删除写屏障两种，Go语言结合了它们的优点，提出了混合写屏障机制。
4. 并发执行: Go语言的垃圾回收器是并发的，这意味着垃圾回收可以在程序运行的同时进行，从而减少了程序停顿的时间，提高了程序的性能。此外，Go语言的垃圾回收器还提供了调优参数，如GC系数，用于控制垃圾回收的频率和开销。

总之，Go语言的垃圾回收器采用了标记-清除算法、三色标记法、写屏障技术和并发执行等特性，从而实现了高效、自动的内存管理，减少了程序员的负担，提高了程序的性能和稳定性。



# gin框架的路由是怎么处理的？
gin框架的路由处理主要依赖于其高性能的路由分发器httprouter。httprouter负责将不同方法的多个路径分别注册到各个处理函数，当收到请求时，它负责快速查找请求的路径是否有相对应的处理函数，并进行下一步业务逻辑处理。

gin框架的路由实现使用了类似前缀树（radix tree）的数据结构，这种数据结构只需要遍历一遍字符串即可，因此其时间复杂度为O(n)。这种实现方式相比传统的根据“/”把路由切分成多个字符串数组，然后按照相同的前子数组把路由构造成树的结构的方式（时间复杂度为O(2n)）更为高效。

Engine是gin框架最重要的数据结构，它是框架的入口。通过Engine对象，我们可以定义服务路由信息、组装插件、运行服务等。


# mysql索引结构skip?

# B+树和B树有什么区别?
1. 节点结构：B树的每个节点（包括内部节点和叶子节点）都存储数据，而B+树只有叶子节点存储数据，内部节点仅作为索引使用，存储关键字和指向子节点的指针。
2. 指针的使用：在B+树中，内部节点的指针用于连接子节点，叶子节点的指针则用于连接相邻的叶子节点，形成一个有序的链表。而在B树中，指针主要用于连接子节点，叶子节点之间没有指针连接。
3. 检索方式：B树既支持随机检索也支持顺序检索，而B+树主要支持顺序检索。由于B+树的所有数据都存储在叶子节点中，且叶子节点通过指针连接，因此可以方便地进行范围查询和顺序访问。
4. 空间利用率和IO效率：B+树的空间利用率更高，因为内部节点不存储数据，可以容纳更多的索引项，从而降低了树的高度。此外，B+树的IO效率也更高，因为每次磁盘IO可以加载更多的索引项，减少了IO次数。
5. 查询效率：B+树的查询效率通常比B树更稳定，因为所有数据都存储在叶子节点中，每次查询的路径长度相对固定。而B树的查询效率可能会受到数据分布和查询模式的影响。
6. 增删操作的复杂性：在进行增删操作时，B树可能需要重新调整树结构以保持平衡，这增加了操作的复杂性。相比之下，B+树在增删操作时不需要调整树结构，因此相对更简单和高效。

# sql查询性能瓶颈处理方式
SQL查询性能瓶颈的处理方式主要包括软优化和硬优化两个方面。软优化主要是操作数据库，通过优化SQL语句、使用缓存、添加索引、数据库读写分离、分库分表等方式来提高查询性能。硬优化则是操作服务器硬件及参数设置，如升级硬件、调整操作系统参数等。

1. 优化SQL语句：通过调整SQL语句的结构、使用更合适的查询语句、避免全表扫描等方式来提高查询效率。同时，可以使用数据库的查询执行计划工具来查看SQL语句的执行情况，进一步优化。
2. 使用缓存：将热点数据放入缓存中，减少数据库的访问次数，从而提高查询性能。常见的缓存技术包括Redis、Memcached等。
3. 添加索引：通过添加索引来加快查询速度，但需要注意避免过度索引导致性能下降。在添加索引时，需要综合考虑查询频率、数据更新频率等因素。
4. 数据库读写分离：将读操作和写操作分离到不同的数据库服务器上，从而提高系统的并发处理能力。这种方式需要应用层进行相应的改造，确保读写分离的正确性和一致性。
5. 分库分表：当单表数据量过大时，可以通过分库分表的方式来降低单表的数据量，从而提高查询性能。分库分表需要综合考虑数据的分布、访问频率等因素，同时需要进行相应的数据迁移和应用改造。
6. 升级硬件：当数据库服务器的硬件性能成为瓶颈时，可以考虑升级硬件，如增加内存、提高CPU性能等。
7. 调整操作系统参数：通过调整操作系统的参数设置，如文件描述符数量、网络参数等，来提高数据库的性能。


# sql索引优化方式，explain字段含义?
1. 选择合适的索引类型
   * B-Tree索引：大多数数据库默认的索引类型，适用于大多数场景。
   * Hash索引：适用于等值查询，不适用于范围查询。
   * 空间索引：用于地理空间数据类型。
   * 全文索引：用于文本搜索。
2. 创建复合索引
   * 根据查询条件创建复合索引，确保索引的列顺序与查询条件一致。
3. 避免过度索引
   * 每个额外的索引都会增加写操作的开销。
   * 定期审查和优化索引。
4. 使用覆盖索引
   * 如果查询只需要索引中的信息，则无需访问表数据，这称为覆盖索引。
5. 删除无用的索引
   * 删除那些从未被使用或很少使用的索引。
6. 索引选择性
   * 高选择性的索引（唯一索引）通常比低选择性的索引（如性别字段）更有效。
7. 考虑查询的排序和分组
   * 如果查询经常需要排序或分组，考虑在这些列上创建索引。
8. 使用EXPLAIN分析查询
   * id: 查询标识符。
   * select_type: 查询类型（如SIMPLE, SUBQUERY, DERIVED等）。
   * table: 输出结果集的表的名称。
   * partitions: 匹配的分区。
   * type: 连接类型（如ALL, index, range, ref, eq_ref, const, system, NULL）。
   * possible_keys: 可能应用的索引。
   * key: 实际使用的索引。
   * key_len: 使用的索引的长度。
   * ref: 哪些列或常量被用作索引查找的参考。
   * rows: 估计要检查的行数。
   * Extra: 包含不适合其他列但十分重要的额外信息。


# GMP具体的调度策略
GMP（Goroutine, Machine, Processor）是Go语言运行时（runtime）中的调度模型，用于管理并发执行的任务。GMP模型中的三个关键组件是G（Goroutine）、M（Machine）和P（Processor）。在这个模型中，G是表示一个执行的协程，M代表一个内核线程，而P则代表一个逻辑处理器，它封装了执行G所需的上下文信息。

GMP模型的具体调度策略如下：

1. 全局队列与本地队列：Go运行时维护了一个全局的G队列，用于存放等待运行的Goroutine。每个P也有自己的本地队列，存放从全局队列获取的、或者由其他P通过“work stealing”机制偷取过来的Goroutine。
2. P与M的绑定：每个P都会绑定一个M，这样G就可以在M上执行。当M阻塞时（例如进行系统调用），P会尝试寻找另一个空闲的M进行绑定，或者从其他P的本地队列中“偷取”Goroutine来运行。
3. 调度循环：在每个调度循环中，P会尝试从本地队列中取出Goroutine来执行。如果本地队列为空，P会尝试从全局队列中取出Goroutine，或者通过“work stealing”机制从其他P的本地队列中偷取Goroutine。
4. work stealing机制：当P的本地队列为空时，它会尝试从其他P的本地队列中“偷取”Goroutine来执行。这种机制有助于平衡不同P之间的负载，避免某些P过于繁忙而其他P空闲。
5. 抢占式调度：Go的调度器采用了一种抢占式调度策略，即一个Goroutine最多只能占用CPU一段时间（默认为10ms），之后就会被调度器抢占，将CPU让给其他等待运行的Goroutine。这有助于防止某些长时间运行的Goroutine饿死其他短时间的Goroutine。
6. 利用并行：通过设置环境变量GOMAXPROCS，可以控制P的数量，从而限制同时运行的Goroutine数量。这有助于在多核CPU上实现并行执行。

# B+树细节优势，和哈希索引的区别，是为了解决什么问题？
B+树和哈希索引是两种常见的数据库索引结构，它们各有特点和优势，适用于不同的查询场景。以下是B+树索引的细节优势以及与哈希索引的区别：

B+树索引的优势：

1. 有序性：B+树索引中的数据按照键值有序排列，这使得范围查询（如区间查询、排序）非常高效。
2. 高度平衡：B+树索引中的所有叶子节点位于同一层级，这意味着查询时的IO操作次数相对较少，提高了查询效率。
3. 节点分裂与合并：B+树在插入和删除数据时，通过节点的分裂与合并操作保持树的平衡，从而确保查询性能的稳定。
4. 支持顺序访问：由于叶子节点通过指针连接形成有序的链表，B+树索引支持顺序访问，这在某些应用场景中非常有用。

哈希索引与B+树索引的区别：

1. 数据结构：哈希索引基于哈希表实现，而B+树索引是一种多路径的平衡搜索树。
2. 查询方式：哈希索引通过计算哈希值直接定位到数据，而B+树索引则需要从根节点开始逐层搜索。因此，哈希索引在等值查询时速度更快，但不适用于范围查询和模糊匹配查询。
3. 数据有序性：B+树索引中的数据有序，而哈希索引中的数据是无序的。
4. 索引更新：当数据发生变化时，B+树索引需要更新相应的节点以保持平衡，而哈希索引则只需重新计算哈希值。因此，B+树索引在更新操作上可能更耗时。

B+树索引和哈希索引都是为了解决数据库查询性能问题而设计的。B+树索引适用于需要高效处理范围查询和排序操作的场景，而哈希索引则更适用于等值查询和快速定位数据的场景


# 事务四个特性四个隔离级别
事务的四个特性通常被称为ACID特性，它们分别是：

1. 原子性（Atomicity）：事务是一个不可分割的工作单位，事务中包括的操作要么全部完成，要么全部不完成。也就是说，如果一个事务中的某些操作失败，那么整个事务就会失败，需要回滚到事务开始前的状态。
2. 一致性（Consistency）：事务必须使数据库从一个一致性状态变换到另一个一致性状态。也就是说，一个事务执行前后，数据库中的数据必须保持一致。
3. 隔离性（Isolation）：通常，一个事务所做的修改在最终提交以前，对其他事务是不可见的。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
4. 持久性（Durability）：一旦事务提交，则其结果永久保存在数据库中。即使系统崩溃，重新启动后数据库还能恢复到事务成功结束时的状态

数据库提供的四种隔离级别分别是：

1. 读未提交（Read Uncommitted）：这是最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、不可重复读和幻读。
2. 读已提交（Read Committed）：只允许读取已提交的数据，可以避免脏读，但是可能会出现不可重复读和幻读。
3. 可重复读（Repeatable Read）：在同一事务内，多次读取同一数据返回的结果是一致的，可以避免脏读和不可重复读，但是可能出现幻读。
4. 串行化（Serializable）：这是最严格的隔离级别，完全遵循ACID特性，所有的事务依次逐个执行，可以避免脏读、不可重复读和幻读。

# http  time_wait状态分析
TIME_WAIT 是一个 TCP 协议中的状态，而不是 HTTP 协议特有的。当 TCP 连接关闭时，主动关闭连接的端点（通常是客户端）会进入 TIME_WAIT 状态。这个状态的主要目的是确保网络中延迟的数据包不会被误解为新的连接的一部分。

## 为什么需要 TIME_WAIT 状态？
1. 避免旧的数据包被误解为新连接的数据包: 在网络中，数据包可能会因为各种原因（如网络拥塞、路由延迟等）被延迟到达。如果一个连接刚刚关闭，并且立即尝试建立一个新的连接，那么这些延迟的数据包可能会被误解为新连接的一部分，从而导致错误。为了避免这种情况，TCP 协议设计了一个 TIME_WAIT 状态，让主动关闭连接的端点在关闭连接后等待一段时间，确保所有的延迟数据包都已经从网络中消失。
2. 确保 TCP 协议的正确性: TCP 协议依赖于序列号来确保数据的顺序和完整性。如果一个连接刚刚关闭，并且立即尝试建立一个新的连接，那么新连接的序列号可能与旧连接的序列号发生冲突，这可能会导致混乱。TIME_WAIT 状态确保了在建立新连接之前，旧连接的序列号空间已经完全使用完毕。

## 如何处理 TIME_WAIT 状态
1. 调整 TIME_WAIT 时间：可以通过操作系统参数（如 Linux 上的 tcp_fin_timeout）来调整 TIME_WAIT 状态的持续时间。缩短这个时间可以减少端口资源的占用，但可能会增加网络中延迟数据包被误解的风险。
2. 使用 SO_REUSEADDR 选项：在服务器端，可以通过设置 SO_REUSEADDR 选项来允许在同一端口上重用地址。这可以减少 TIME_WAIT 状态对新连接建立的影响，但需要注意的是，在某些情况下，这可能会导致数据混淆或其他问题。
3. 使用更现代的协议：HTTP/1.1 和 HTTP/2 协议通过长连接（持久连接）减少了 TIME_WAIT 状态的影响。这些协议允许在单个 TCP 连接上发送多个 HTTP 请求，从而减少了连接的建立和关闭次数。

TIME_WAIT 状态是 TCP 协议中的一个重要机制，用于确保网络数据的正确性和可靠性。


# nginx负载均衡策略
1. 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器。如果后端服务器down掉，nginx会自动剔除该服务器。这种策略适合每个后端服务器的配置相当，无状态且短平快的服务使用。
2. 权重（weight）方式：在轮询策略的基础上指定轮询的几率。权重越高，分配到需要处理的请求越多。此策略可以与least_conn和ip_hash结合使用，适合服务器的硬件配置差别比较大的情况。
3. IP_HASH：指定负载均衡器按照基于客户端IP的分配方式。这个方法确保了相同的客户端的请求一直发送到相同的服务器，以保证session会话。这样每个访客都固定访问一个后端服务器，可以解决session不能跨服务器的问题。
4. least_conn：把请求转发给连接数最少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。least_conn策略可以解决这个问题。

# es内部实现原理，如何保证数据一致性，如何降低压力
Elasticsearch（简称ES）是一个基于Lucene的搜索服务器，用于全文搜索、结构化搜索、分析，并能将其部署到一个或多个服务器上。它通常被用作某种形式的数据仓库，其设计能够处理大量的数据并提供近实时的搜索和分析能力。

## 内部实现原理
1. 倒排索引：ES的核心是倒排索引，这是一种能够快速检索文档的技术。它首先将文档内容分解为单词或词组（称为term），然后将这些term映射到文档列表上。
2. 分片和副本：ES通过分片（Sharding）和副本（Replication）机制实现数据的水平扩展和高可用性。一个ES集群可以包含多个节点，每个节点可以存储一个或多个分片，而每个分片可以有多个副本。
3. 分布式架构：ES是一个分布式系统，其内部使用ZooKeeper或内置的Raft选举机制进行集群管理。所有的节点都是对等的，并且可以互相通信。

## 如何保证数据一致性
1. 事务日志（Transaction Log）：每个分片都有一个事务日志，用于记录所有对分片的更改。这确保了即使在发生故障时，已提交的更改也不会丢失。
2. 复制：通过创建分片的副本，ES可以提高数据的可用性和一致性。副本不仅用于故障恢复，还可以用于查询，从而提高查询性能。
3. 分布式一致性协议：ES使用一种称为“基于主-从的复制”的分布式一致性协议。每个分片都有一个主节点和零个或多个副本节点。主节点负责处理写请求，并将更改复制到副本节点。

## 如何降低压力
1. 水平扩展：通过增加节点数量，ES可以水平扩展其存储和计算能力。这允许您处理更多的数据和查询请求。
2. 分片策略：通过合理地设置分片的数量和副本的数量，您可以平衡存储和计算负载。例如，您可以增加分片的数量以分散存储负载，或增加副本的数量以提高可用性和查询性能。
3. 查询优化：通过优化查询语句和使用过滤器（Filter）而不是查询（Query）来减少不必要的计算。此外，利用ES的查询缓存和预热查询功能也可以提高查询性能。
4. 硬件优化：通过升级硬件（如增加内存、使用更快的磁盘等）或优化ES的配置设置（如调整JVM参数、增加线程池大小等）来提高ES的性能和稳定性。


# linux查看磁盘、io、内存情况的命令
## 查看磁盘情况：

1. df 命令：显示文件系统的磁盘空间使用情况。
   * -h 参数：以人类可读的方式显示磁盘空间。
2. du 命令：估算文件和目录的磁盘空间使用量。
   * -h 参数：以人类可读的方式显示磁盘空间。
   * /path/to/directory：要查看的目录路径。
3. lsblk 命令：列出块设备的信息，包括磁盘、分区和挂载点等。
4. fdisk 命令：查看和管理磁盘分区。
   * -l 参数：列出所有的磁盘分区信息。
5. blkid 命令：显示块设备的属性，包括设备的UUID、文件系统类型等。
   * /dev/sda1：要查看的设备。

## 查看IO情况：

1. iostat 命令：查看系统的磁盘IO情况。
   * -x 参数：显示关于磁盘读写速度、平均响应时间、IO队列长度等信息。
   * 1：每隔1秒输出一次IO信息。
2. vmstat 命令：查看系统的虚拟内存、进程和IO情况。
3. dstat 命令：查看CPU、内存、磁盘、网络和IO等方面的实时统计信息。

## 查看内存情况：

1. free 命令：显示系统的内存使用情况。
2. top 命令：实时的系统监视器，可以显示内存使用情况。
   * Shift + M：按内存使用情况排序。
3. vmstat 命令：显示系统的虚拟内存统计信息。
4. ps 命令：显示当前运行的进程信息，并可以通过选项按内存使用量排序。
   * aux --sort -rss：按内存使用量从高到低的顺序显示进程信息。

# 分库分表联表查询有哪些方式
## 单表情况  

1. 应用层分页：将查询条件分发到各个数据库，然后在应用层合并结果集并进行分页。这种方案可以实现比较灵活的分页查询，但是需要考虑分组、排序等复杂的情况，还需要处理分页边界问题。
2. 数据库中间件：使用数据库中间件来屏蔽分库分表对应用的影响，中间件会将应用发出的SQL语句转换成针对多个数据库的查询语句，并将结果集进行合并。这种方案可以实现比较灵活的查询，但需要引入额外的中间件，可能会影响性能和稳定性。
3. 分库分表框架：使用分库分表框架来实现跨多个数据库和表的查询，例如Sharding-JDBC等。这种方案可以实现透明化的分库分表操作，但需要引入额外的框架和配置，可能会增加复杂度。

## 多表情况
1. 利用UNION或UNION ALL：将多个查询结果集合并成一个结果集返回。
2. 建立主表：将需要联表查询的字段放在一张主表中，并做好索引。记录下用户经常查询的条件，把查出的数据缓存，以便用户经常调用。
3. 多线程处理：每个子表各开一个线程分别查询数据，然后进行合并。但需要注意的是，线程数不能开太多，要根据处理器个数和总连接数来衡量。


无论采用哪种方式，都需要考虑分页边界问题和性能问题。在分页查询时，需要确保每个分库分表中的数据都被查询到，并且可以正确排序和分页。


# 覆盖查询&回表查询
覆盖查询（Covering Index）：当查询所需的所有列都包含在索引中时，就会发生覆盖查询。这意味着数据库引擎可以直接从索引中获取所需的所有数据，而无需再访问表中的数据行。因为避免了额外的表访问，所以覆盖查询通常更高效。在InnoDB存储引擎中，如果一个查询可以利用主键索引获取所有所需数据，就可以实现覆盖查询。

回表查询（Secondary Index Lookup）：当查询无法从索引中获取所需的所有列数据时，数据库引擎必须执行回表查询。这通常发生在普通索引（非主键索引）中，因为普通索引的叶子节点只包含索引列的值和主键值，而不包含其他列的数据。当查询需要获取表中的其他列数据时，数据库引擎会首先使用索引定位到主键值，然后再通过主键值去表中查找完整的行记录。这个过程被称为回表查询，因为它需要回到表中查找数据。回表查询通常比覆盖查询更耗时，因为它涉及到额外的表访问。

为了提高查询性能，数据库优化者通常会尝试创建覆盖索引，即将查询中所需的列包含在索引中，以减少回表查询的需要。然而，过多的索引也会增加数据库的存储空间和维护成本，因此需要在覆盖查询和回表查询之间找到平衡。


# 聚簇索引&非聚簇索引
存储索引的物理区分方式  
* 聚簇索引节点中存储的是数据
* 非聚簇索引节点中存储的是行记录的地址

mysql中Innodb使用的是聚簇索引,data目录中包含两个文件（表节结构定义文件，表数据文件）   
myisam用的是非聚簇索引，data目录中包含3个文件（表结构定义文件，索引文件，数据文件）



# go实现不重启热部署
用的是overseer这个包，采用主从进程设计，有父进程创建监听 socket ，然后fork-exec派生出子进程，将全部监听 socket 继承给子进程，业务逻辑由子进程来运行。  
在重启的过程中，旧的子进程不在接受请求，而转移到新的子进程中，旧的子进程处理所有请求后就会推出



# go性能分析工具
## 服务性采集
1. net/http/prof
2. gops 用于非web服务

## 非服务性采集
1. runtime/prof
2. go test

使用graphviz 可以图形化结果  
go tool pprof 本地文件/url  



# tcp如何保证稳定性
1. 字节流传输：TCP将应用层发送的数据划分成以字节为单位的报文段，并进行序列号标记，以确保数据传输的有序性。
2. 确认重传机制：TCP在通信过程中采用确认和重传机制。当接收方收到报文段后，会进行确认(Ack)操作。如果发送方没有收到确认，则会重新传送该报文段。
3. 滑动窗口机制：TCP利用滑动窗口机制实现流量控制和拥塞控制。通过限制发送方窗口大小，防止发送速度过快，而接收方处理不及时导致的包丢失等问题。同时，可以根据网络拥塞情况来动态调整窗口大小，保证网络的稳定性和可靠性。
4. 头部校验和：在TCP传输过程中，每个报文段都会添加一个头部校验和，以检测数据在传输过程中是否损坏或者被篡改。如果发现数据损坏，则会进行重传，以确保数据的完整性和准确性。
5. 连接管理：TCP通过三次握手建立连接，并通过四次挥手关闭连接，确保连接的稳定性和可靠性。

# http和http2区别
1. 二进制传输：HTTP/2采用二进制传输，而HTTP/1.x使用文本传输。二进制传输使得HTTP/2更为高效和安全，因为二进制数据可以被机器直接解析，减少了由于文本带来的二义性。此外，二进制传输的单位是帧和流，帧组成了流，同时流还有流ID标示。
2. 多路复用：HTTP/2支持多路复用，这意味着一个HTTP/2连接可以并行处理多个请求，而不需要为每个请求建立新的连接。通过流ID，HTTP/2可以在同一个连接中同时传输多个请求，降低了连接的数量，提高了网络的吞吐量。
3. 头部压缩：HTTP/2通过gzip和compress对头部进行压缩，然后在客户端和服务器端同时维护一份头部索引表。这样，每次传输只需要传输索引ID，通过索引ID查询表头的值，从而缩小了头部容量，间接提升了传输效率。
4. 服务端推送：HTTP/2支持服务端推送，即服务器可以在未经客户端许可的情况下，主动向客户端推送内容。这避免了客户端需要逐个请求资源，降低了响应时间。

# https的连接过程
1. 客户端发起请求：客户端（通常是浏览器）向服务器发起建立连接的请求，同时发送客户端支持的一套加密规则，包括对称加密、非对称加密、摘要算法等。
2. 服务器响应并选择加密方式：服务器接收到请求后，从中选出一组加密算法和hash算法，并将自己的身份信息以证书的形式发送给客户端。证书包括网站地址、加密公钥（用于非对称加密）和证书颁布机构等信息。
3. 客户端验证服务器证书：客户端收到服务器证书后，会验证证书的合法性。验证内容包括证书是否过期、证书颁发机构（CA）是否可靠、发行者证书的公钥是否能正确解开服务器证书的“发行者的数字签名”，以及服务器证书上的域名是否和服务器的实际域名相匹配等。
4. 生成随机密钥并进行加密：如果证书验证通过，或者即使证书不受信任，客户端会生成一个随机密钥（用于对称加密），并用服务器提供的公钥（非对称加密）对密钥进行加密。然后，采用hash算法对握手信息进行摘要计算，再用随机密钥（对称加密算法）对摘要进行加密。最后，将随机密钥和摘要发送给服务器。
5. 服务器解密并验证握手信息：服务器收到加密的随机密钥和摘要后，用自己的私钥解密获得随机密钥，再解密得到hash摘要值，然后验证握手信息是否一致。
6. 产生主通讯密码：如果服务器要求客户的身份认证，服务器必须检验客户证书和签名随机数的合法性。验证通过后，服务器和客户端将使用相同的对称加密密钥进行通讯。这个对称密钥用于SSL协议的安全数据通讯的加解密通讯。
7. 建立安全连接：客户端和服务器通过交换信息，确认将使用之前产生的对称密钥作为后续通讯的加密密钥，并通知对方握手过程结束。此时，双方已经建立了安全的HTTPS连接，可以开始进行加密的数据通讯。

HTTPS在HTTP的基础上增加了一个TLS层，所有的数据都先经过TLS加密后再发送给TCP进行传输。这种加密方式确保了数据在传输过程中的安全性和完整性，防止了数据泄露和被篡改。  




# kafka如何做到高可用skip
# 分布式锁如何实现
1. 基于数据库实现分布式锁  
   在数据库中创建一张表，用于记录锁的占用情况。当需要获取锁时，向该表中插入一条记录，表示占用该锁。其他线程或进程在尝试获取锁时，会先查询该表，判断锁是否已被占用。如果锁已被占用，则等待或尝试获取其他锁；如果锁未被占用，则插入一条记录，表示占用该锁。释放锁时，只需删除对应的记录即可。
但是，基于数据库实现分布式锁存在一些问题，如性能瓶颈、单点故障等。因此，在实际应用中，通常会选择其他更高效的实现方式。

2. 基于Redis实现分布式锁   
   当需要获取锁时，使用SETNX命令尝试设置一个键值对，如果设置成功，则表示占用该锁；如果设置失败（即键已存在），则表示锁已被其他线程或进程占用。释放锁时，使用DEL命令删除对应的键值对即可。
为了提高可靠性，可以在设置键值对时设置一个过期时间，以防止因进程崩溃等原因导致锁无法被释放。此外，还可以使用Redis的Lua脚本功能来确保操作的原子性。
3. 基于zookeeper实现分布式锁   
   在Zookeeper中创建一个节点作为锁，当需要获取锁时，尝试在该节点下创建一个子节点（即临时节点或顺序节点）。如果创建成功，则表示占用该锁；如果创建失败（即节点已存在），则表示锁已被其他线程或进程占用。释放锁时，只需删除对应的子节点即可。
Zookeeper具有强一致性、高可用性和容错性等特点，因此基于它实现的分布式锁也具有较高的可靠性和稳定性。但是，与基于缓存服务的实现方式相比，基于Zookeeper的实现方式性能可能稍逊一些。因此，在选择实现方式时需要根据具体场景进行权衡和选择。
4. 基于Etcd实现分布式锁
   在ETCd中创建一个键值对，键作为锁的名称，值可以是任意信息。由于ETCd支持原子操作，这可以确保在同一时间只有一个客户端能够成功创建锁。在ETCd中创建一个键值对，键作为锁的名称，值可以是任意信息。由于ETCd支持原子操作，这可以确保在同一时间只有一个客户端能够成功创建锁。

# 读扩散&写扩散
读扩散是指在分布式系统中，由于数据的复制和缓存等原因，当一条数据被更新后，在多个节点中都存在该数据的副本。当其他节点请求该数据时，可能会读取到过期的数据，因为该节点上的数据还未被更新。这导致其他节点上的数据过期，从而读取到过期数据的现象。

写扩散则是指在分布式系统中，当一条数据被更新后，需要将该数据的更新操作同步到多个节点中的副本，以保证数据的一致性。这种同步操作可能需要耗费较多的时间和网络带宽，对系统性能产生一定的影响。

为了解决读扩散和写扩散的问题，分布式系统中通常会采用一些策略和技术。例如，对于读扩散问题，可以使用版本号或时间戳等机制来比较数据的版本或时间戳，从而确保读取到的数据是最新的。对于写扩散问题，可以采用异步复制或延迟复制等技术，将数据的同步操作放到后台进行，避免对系统性能造成较大的影响。

此外，分布式共识算法，如Paxos和Raft协议等，也可以确保分布式系统中节点间的一致性，从而解决读扩散和写扩散问题。这些算法可以确保节点达成共识，协同完成数据的读写操作，从而保证了系统的正确性和可靠性


# goroutine创建数量有限制吗？
Goroutine的创建数量没有直接的限制。Goroutine是Go语言中的轻量级线程，由Go运行时环境管理。在理论上，你可以创建数以百万计的Goroutine，但实际上的数量受到系统资源（如内存）的限制。因为每个Goroutine都会占用一定的内存，如果无限制地创建，可能会导致内存耗尽。

但是，Go语言的运行时环境对Goroutine的数量也有一定的管理机制。当Goroutine的数量达到一定的阈值时，调度器会限制新的Goroutine的创建，直到已有的Goroutine执行完毕并释放资源。这个阈值并不是固定的，而是根据系统的实际情况动态调整的。

因此，虽然Goroutine的创建数量没有直接限制，但在实际使用中，仍需要根据系统的资源情况来合理控制Goroutine的数量，避免出现资源耗尽的问题。同时，也需要注意Goroutine的创建和销毁时机，避免出现内存泄漏等问题。


# go并发机制
这种机制主要基于goroutine和CSP（通信顺序过程）概念。  

1. Goroutine：Goroutine是Go语言中的轻量级线程，由Go运行时环境管理。与传统的线程相比，Goroutine的上下文切换开销要小很多，因此可以创建数以百万计的Goroutine。Goroutine的创建非常简单，只需使用go关键字后跟一个函数调用即可。
2. CSP（通信顺序过程）：CSP是Go并发机制的理论基础，强调通过通信来共享内存，而不是通过共享内存来通信。这有助于简化并发编程模型，并减少竞态条件和死锁的风险。在Go中，可以使用channel来实现Goroutine之间的通信。Channel是一个类型安全的、阻塞的通信管道，用于在Goroutine之间传递数据。
3. 调度与执行：Go运行时环境负责Goroutine的调度和执行。调度器会根据Goroutine的优先级和系统的负载情况来调度Goroutine的执行。当Goroutine执行完毕或阻塞时（如等待I/O操作完成），调度器会将其挂起，并切换到其他可执行的Goroutine。


# 线程协程区别
1. 调度方式：线程由操作系统内核进行调度，可以在不同的核心上并行执行。而协程的调度则是由程序员或运行时环境显式地控制，在单个线程内通过协作式调度来实现并发。
2. 并发性：线程是并发执行的，多个线程可以同时执行不同的任务。而协程是协作式的，只有一个协程在执行，其他协程需要等待当前协程主动释放控制权才能执行。
3. 内存消耗：线程需要独立的堆栈空间，每个线程都有自己的堆栈，因此线程的内存消耗较大。而协程共享线程的堆栈，因此协程的内存消耗较小。
4. 切换开销：线程的切换需要保存和恢复线程的上下文，这涉及到内核态和用户态之间的切换，开销较大。而协程的切换只需要保存和恢复协程的上下文，开销较小。


# 锁的可重入
锁的可重入性（Reentrant）是指同一个线程在已经持有锁的情况下，再次获取该锁时不会被阻塞，而是可以继续获取该锁。

可重入锁是一种允许同一个线程多次获得同一把锁的机制。然而，Go的设计者故意避免了这种复杂性，因为它们认为可重入锁会导致代码更加复杂和难以维护。使用通道和协程的方式鼓励开发者写出更简单、更清晰且更容易理解的并发代码。

Go的标准库提供了基本的同步原语，如互斥锁（sync.Mutex），但这些锁是非重入的。如果一个 goroutine 试图两次锁定同一个互斥锁，它会死锁。

这强制开发者更仔细地考虑锁的使用，从而减少死锁和其他并发问题的可能性。Go 语言不支持可重入锁（reentrant locks），主要是因为它的并发模型和设计哲学。在Go中，推荐的并发处理方式是通过通道（channels）和协程（goroutines）来进行，而不是传统的锁和线程模型。这种方法被称为“以通讯来共享内存，而非以共享内存来通讯”。

当然也可用go来实现可重入的锁，获取Goroutine的ID,再维护一个计数器，即可

# 常用限流算法
1. 固定窗口算法：在指定的时间段内只允许通过固定次数的请求。例如，1秒到10秒这个时间段内允许通过100个请求。但是，这种算法存在临界值问题，如果请求集中在一个时间窗口内，可能会超过系统处理能力。
2. 滑动窗口算法：为了解决固定窗口算法中的临界值问题，滑动窗口算法将固定窗口中的时间段进行细分，分成更小的时间窗口。这样可以平滑突发流量，减少临界值问题。
3. 漏桶算法：漏桶算法有一个固定容量的漏桶和固定的流出速度。当请求进入时，先放入漏桶中。如果请求速度小于流出速度，则请求可以正常执行；如果请求速度大于流出速度，则按照流出速度执行请求，相当于进行了限流。Nginx的限流算法就是使用的漏桶算法。
4. 令牌桶算法：令牌桶算法有一个固定容量的令牌桶，系统以一定的速度往令牌桶中放令牌。当请求到来时，先从令牌桶中获取令牌，获取到令牌才有权限访问系统。如果请求速度小于令牌生成速度，则请求可以正常执行；如果请求速度大于令牌生成速度，则超出部分的请求将被拒绝，实现了限流。Gateway网关用到的限流算法就是令牌桶算法

Golang标准库中实现的限流器使用了令牌桶算法（Token Bucket）。在Golang的golang.org/x/time/rate包中提供了限流器的实现。


# rpc调用过程
1. 客户端（Client）以本地调用的方式发起调用。
2. 客户端存根（Client stub）收到调用后，负责将被调用的方法名、参数等打包编码成特定格式的消息体。
3. 客户端存根将消息体通过网络发送给服务端。
4. 服务端存根（Server stub）收到通过网络接收到的消息后，按照相应格式进行拆包解码，获取方法名和参数。
5. 服务端存根根据方法名和参数进行本地调用。
6. 被调用者（Server）本地调用执行后将结果返回给服务端存根。
7. 服务端存根将返回值打包编码成消息。
8. 通过网络发送给客户端。
9. 客户端存根收到消息后，进行拆包解码，返回给客户端。
10. 客户端得到本次RPC调用的最终结果

# 熔断降级开源框架
熔断降级开源框架是一种用于提高服务可靠性的工具，适用于依赖大量外部服务的业务系统。当系统出现不稳定因素（如响应时间变长，错误率上升）的时候，熔断降级框架会暂时切断服务的调用，等待一段时间再进行尝试，防止给不稳定服务“雪上加霜”，同时也保护服务的调用方不被拖垮。

其中，Hystrix是一个开源的熔断降级框架，用于处理分布式系统的延迟和容错。它实现了断路器模式，当某个服务的调用连续多次失败达到一定的阈值，断路器会打开，后续对该服务的调用请求将不再继续，直接返回错误响应，从而避免系统资源的浪费。此外，Hystrix还提供了降级机制，当某个服务出现故障或者性能下降时，可以执行备用的逻辑，保证系统的整体稳定性。

另一个值得关注的熔断降级开源框架是Sentinel。Sentinel是阿里巴巴开源的，面向分布式服务架构的流量控制组件，主要以流量为切入点，从限流、流量整形、熔断降级、系统自适应保护等多个维度来帮助开发者保障微服务的稳定性。Sentinel支持两种熔断策略：基于响应时间（慢调用比例）和基于错误（错误比例/错误数），可以有效地针对各种不稳定的场景进行防护。


# serviceMash
Service Mesh（服务网格）是一种专门用于处理服务间通信的基础设施层。它通常是由一组轻量级的网络代理组成，这些代理与应用程序一起部署，但对应用程序是透明的。Service Mesh的目标是在云原生应用复杂的服务拓扑中实现可靠的请求传递。

Service Mesh可以看作是传统代理的升级版，用来解决当前微服务框架中出现的问题（如网络相关的问题）。传统意义的代理主要强调底层网络数据，而Service Mesh则更强调程序级别的API级别的通用功能，与业务逻辑有一定的关联。它把和网络API基本配置相关的通用功能独立出来，并提供一个公共的数据和控制面板，方便用户使用。

Service Mesh的基本结构是一组与应用一起部署的轻量级服务代理和应用逻辑的服务，它们共同存在，并且对于应用服务是透明的。这种设计使得Service Mesh可以专注于处理服务间的通信，从而实现业务升级和微服务SDK升级的解耦，降低异构系统的维护成本。

此外，Service Mesh类似于TCP/IP协议栈，它抽象了在服务之间可靠地传递请求的机制。与TCP不同的是，Service Mesh有更高的目标，即为应用运行时提供统一的、应用层面的可见性和可控性。

总之，Service Mesh是一种用于处理云原生应用中服务间通信的基础设施层，它通过轻量级的网络代理实现可靠的请求传递，并提供统一的、应用层面的可见性和可控性。


# 什么操作会影响联表查询效率
1. 未使用索引：当进行联表查询时，如果连接的字段没有建立索引，查询效率会大大降低。因此，为经常用于连接的字段建立索引是非常重要的。
2. 使用了不恰当的连接类型：SQL支持多种连接类型，如INNER JOIN、LEFT JOIN、RIGHT JOIN和FULL JOIN等。选择不恰当的连接类型可能会导致查询效率降低。例如，当只需要获取两个表中匹配的数据时，使用INNER JOIN通常比使用LEFT JOIN或RIGHT JOIN更高效。
3. 查询条件复杂：如果查询条件复杂，涉及多个字段、多个表以及复杂的逻辑运算，可能会导致查询效率降低。
4. 数据量大：当连接的两个表的数据量都很大时，联表查询的效率可能会受到影响。这种情况下，可以考虑对表进行分区或使用其他优化策略。
5. 使用了函数或计算：在查询条件中使用函数或进行复杂的计算可能会降低查询效率，因为数据库可能无法有效地使用索引。
6. 未使用合适的查询优化器提示：某些数据库允许使用查询优化器提示来指导查询的执行。如果提供了不恰当的提示，可能会影响查询效率。
7. 数据库统计信息不准确：数据库优化器依赖于统计信息来选择最佳的查询执行计划。如果统计信息不准确或过时，可能会导致查询效率降低。
8. 硬件和配置限制：硬件性能（如CPU、内存、磁盘速度）和数据库配置（如内存分配、并行度等）也可能影响联表查询的效率。

为了提高联表查询的效率，可以考虑以下策略：

1. 为连接字段建立索引。
2. 选择合适的连接类型。
3. 简化查询条件。
4. 对大表进行分区。
5. 定期更新数据库的统计信息。
6. 优化数据库的配置和硬件性能。


# 一个sql的查询过程
1. 解析（Parsing）:
   * 语法检查：首先，数据库检查SQL查询的语法是否正确。如果查询包含语法错误，数据库将返回一个错误。
   * 语义检查：然后，数据库进行语义检查，确保查询中引用的所有表、列和函数都存在，并且用户有权限执行查询。
   * 生成解析树：数据库将SQL查询转换成一个解析树（parse tree），这是查询的一个抽象语法表示。
2. 优化（Optimization）:
   * 查询重写：数据库可能重写查询，以使其更有效。例如，它可能会转换联接的顺序或重写子查询。
   * 选择执行计划：数据库评估多个可能的执行计划，并选择其中效率最高的一个。这包括确定如何最好地访问数据（例如，使用索引还是全表扫描）、如何连接多个表以及如何处理排序和分组。
   * 统计信息：数据库使用表的统计信息（如行数、列值分布等）来帮助选择最佳执行计划。

3. 执行（Execution）:
   * 开始执行计划：数据库开始执行选择的执行计划。这可能涉及读取数据、连接表、应用过滤条件、排序和分组等。
   * 获取数据：根据执行计划，数据库从磁盘或内存中检索数据。如果查询涉及多个表，数据库将按照指定的顺序和方式连接它们。
   * 处理结果：数据库处理查询结果，这可能包括排序、分组、聚合等。
4. 返回结果:
   * 结果集：一旦处理完查询，数据库将结果集返回给客户端。这通常是一个表格形式的数据集，包含查询请求的数据。
   * 错误处理：如果在查询执行过程中出现任何错误（如权限问题、资源不足等），数据库将返回相应的错误消息。


# redis单线程是如何做到支持高并发的
1. 基于内存的数据存储：Redis将所有数据都存储在内存中，这使得数据读取和写入速度非常快，远超过磁盘操作的速度。由于内存访问速度非常快，Redis可以在单个线程中高效地处理大量并发请求。
2. 非阻塞I/O模型：Redis采用单线程的非阻塞I/O模型，这意味着Redis可以在等待数据到达或数据发送完成的过程中继续处理其他请求，而不会阻塞整个线程。这种模型使得Redis能够同时处理多个客户端请求，提高了并发处理能力。
3. 高效的数据结构：Redis提供了多种高效的数据结构，如字符串、哈希表、列表、集合、有序集合等。这些数据结构在内存中使用非常节省，并且在处理数据时具有很高的效率。Redis通过使用这些数据结构，可以在单个线程中快速完成各种操作，从而提高并发性能。
4. 事件驱动的设计：Redis采用事件驱动的设计，当请求到达时，通过事件处理器直接处理请求，这种设计可以减少线程切换和上下文切换的开销，提高并发处理能力。
5. Lua脚本的支持：Redis支持Lua脚本，可以将多个操作合并成一个原子性操作，从而减少网络延迟和多次调用的开销。这有助于在单个线程中更高效地处理并发请求。

# IO多路复用
IO多路复用是一种同步IO模型，它允许单个线程或进程同时监视多个文件描述符（通常是网络连接），并在这些文件描述符中的任何一个变得可读、可写或有异常情况时通知应用程序进行相应的读写操作。这种模型可以显著提高服务器的吞吐能力，因为它避免了为每个连接创建一个新的线程或进程所带来的开销。

IO多路复用的实现方式主要有三种：select、poll和epoll。   
1. select：是最早的IO多路复用技术，它通过将文件描述符集合从用户空间拷贝到内核空间，然后内核遍历这个集合来检查哪些文件描述符就绪。但是，select存在一些问题，比如它只能监视有限数量的文件描述符（通常是1024个），并且在每次调用select时都需要将文件描述符集合从用户空间拷贝到内核空间，这会导致不必要的开销。
2. poll：是select的改进版，它解决了select的一些限制。poll使用了一个链表来存储文件描述符，而不是使用固定大小的数组，因此它可以监视的文件描述符数量几乎只受限于内存大小。另外，poll在每次调用时不需要将文件描述符集合从用户空间拷贝到内核空间，而是直接在用户空间中进行操作，这减少了不必要的开销。
3. epoll：是Linux特有的IO多路复用技术，它进一步改进了poll的性能。epoll使用了一种基于事件通知的机制，当文件描述符就绪时，内核会直接通知应用程序，而不需要应用程序不断地轮询。此外，epoll还支持水平触发和边缘触发两种模式，以及LT（level trigger）和ET（edge trigger）两种触发方式，这使得它在处理大量并发连接时更加灵活和高效。

# 为什么内存操作很快
1. 物理特性：内存通常是由高速的半导体材料（如DRAM）构成的，这些材料允许数据以非常快的速度被读取和写入。相比之下，硬盘等存储设备则使用机械结构，其读写速度受到机械运动的限制，因此速度较慢。
2. 访问模式：内存中的数据是以连续的字节块形式存储的，这种连续性的存储模式使得计算机可以快速地定位并访问所需的数据。此外，内存通常使用直接寻址模式，即每个内存位置都有一个唯一的地址，这使得访问过程更加高效。
3. 缓存机制：为了提高内存访问速度，现代计算机系统通常会采用多级缓存（如L1、L2、L3缓存）来缓存最近访问过的数据。当CPU需要访问某个内存位置时，它首先会检查缓存中是否已有该数据。如果缓存命中，则可以直接从缓存中读取数据，从而避免了访问主存的延迟。
4. 并行处理：内存通常被设计成支持并行访问，这意味着多个内存位置可以同时被读取或写入。这种并行处理能力使得内存访问速度得到进一步提高。
5. 硬件优化：内存硬件设计通常针对速度进行了优化，例如采用高速的时钟频率、优化数据传输路径等。这些硬件层面的优化都有助于提高内存访问速度。

# k8s各种组件
1. Master 组件：
   * API Server：Kubernetes的主要管理组件，提供HTTP/HTTPS RESTful API（即Kubernetes API）。所有请求都通过此接口进行通信，它是接收、校验并响应所有REST请求的唯一入口。
   * etcd：Kubernetes的主要键值存储系统，用于保存集群的配置信息和各种资源的状态信息。当数据发生变化时，etcd会快速通知Kubernetes相关组件。
   * Scheduler：负责资源的调度，根据预定的调度策略将Pod调度到相应的节点上。
   * Controller Manager：处理集群中的常规任务，包括故障检测、自动扩展、滚动更新等。它由多种controller组成，如replication controller、endpoints controller等。
2. Node 组件：
   * Kubelet：负责管理Pods以及容器、镜像、Volume等，实现对集群节点的管理。
   * Kube-proxy：提供网络代理和负载均衡，实现与Service的通信。
   * Docker Engine：负责节点的容器管理工作。


# gomap并发安全问题，如何解决
1. 使用互斥锁（Mutex）：在对Map进行读写操作之前，先获取锁，操作完成后释放锁。这样可以保证同一时间只有一个goroutine能够对Map进行操作，从而避免了竞争条件 
2. 使用读写锁（RWMutex）：读写锁允许多个goroutine同时对Map进行读操作，但只允许一个goroutine进行写操作。这样可以提高读操作的并发性能。
3. 分片加锁：如果一个操作会导致整个map被锁住，可能会导致性能降低。因此，可以将map分成几个片，按片加锁，以提高并发性能。
4. 使用sync.Map：sync.Map是Go标准库提供的一个并发安全的map实现。它在读多写少的场景下性能较好，但在并发写较多的场景下性能较差。使用sync.Map可以无需手动加锁，但需要注意其使用方式和限制

# 一个进程能创建的线程数量受到哪些制约？
1. 可用虚拟空间：一个进程可用的虚拟空间是有限的，通常情况下是2GB（在32位系统中）或更大（在64位系统中）。每个线程都需要一定的栈空间，因此可用的虚拟空间会限制可创建的线程数量。默认情况下，线程的栈大小是1MB，所以理论上在32位系统中最多只能创建2048个线程。在64位系统中，由于虚拟空间更大，理论上可以创建的线程数量更多，但实际操作中还会受到其他因素的限制。
2. 系统参数限制：虽然Linux没有内核参数来控制单个进程创建的最大线程数，但有一些系统级别的参数可以限制整个系统的最大线程数。例如，/proc/sys/kernel/threads-max表示系统支持的最大线程数，/proc/sys/kernel/pid_max表示系统全局的PID号数值的限制，而/proc/sys/vm/max_map_count则限制了一个进程可以拥有的VMA（虚拟内存区域）的数量。这些参数的值都可能影响到进程能创建的线程数量。
3. 物理内存限制：虽然虚拟空间很大，但实际的物理内存是有限的。每个线程都需要占用一定的物理内存，因此当物理内存被耗尽时，即使虚拟空间还有剩余，也无法再创建新的线程。此外，线程对象本身也会占用非页面内存，当非页面内存被耗尽时，也无法创建新的线程。
4. 线程管理开销：创建和管理大量的线程会带来额外的开销，包括线程切换、上下文保存和恢复等。过多的线程可能会导致性能下降，甚至使程序运行效率变低。


# redis主从同步怎么做的
Redis的主从同步是通过异步复制实现的。主节点负责处理客户端的写操作，并将写操作的日志（命令）发送给从节点。从节点接收到主节点发送的日志后，按照接收的顺序执行这些日志，从而实现主从数据的同步。具体步骤如下：

1. 从服务器连接主服务器，发送SYNC命令。
2. 主服务器接收到SYNC命令后，开始执行BGSAVE命令生成RDB文件，并使用缓冲区记录此后执行的所有写命令。
3. 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令。
4. 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照。
5. 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令。
6. 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令。
完成上述步骤后，从服务器数据初始化完成，此时可以接收来自用户的读请求。此外，主从刚连接的时候进行全量同步，全同步结束后，进行增量同步。当有需要时，从节点可以在任何时候发起全量同步

# k8s基本操作
1. 创建资源: apply
2. 查看资源: get
3. 描述资源: describe
4. 删除资源: delete
5. 进入容器：exec -it pod-name -- ls
6. 查看日志：logs -f

# docker底层实现原理
Docker的底层实现主要基于Linux技术，包含Linux上的命名空间（Namespaces）、控制组（Control groups）和联合文件系统（Union file system）


# docker基本操作
1. 启动Docker：安装完成后，可以使用系统服务命令来启动Docker服务。
2. 镜像管理：
   * 查找镜像：使用docker search命令来搜索官方或其他仓库中的镜像。
   * 下载镜像：使用docker pull命令从Docker Hub或其他仓库下载镜像到本地。
   * 查看本地镜像：使用docker images命令查看已下载的镜像列表。
   * 删除镜像：使用docker rmi命令删除不再需要的镜像。
   * 上传镜像：使用docker push命令将镜像上传到Docker Hub或其他仓库。
3. 容器管理：
   * 创建并启动容器：使用docker run命令基于镜像创建并启动一个容器。
   * 查看运行中的容器：使用docker ps命令查看当前正在运行的容器。
   * 查看所有容器：包括已停止的容器，可以使用docker ps -a命令。
   * 进入容器：使用docker exec -i -t命令进入正在运行的容器并创建交互式会话。
   * 停止容器：使用docker stop命令停止运行中的容器。
   * 重启容器：使用docker restart命令重启已停止的容器。
   * 删除容器：使用docker rm命令删除已停止的容器。
4. 数据卷和容器间通信：
   * 创建数据卷：使用docker volume create命令为容器创建持久化存储。
   * 容器间通信：通过Docker网络功能实现容器间的相互通信。
5. Docker网络：
   * 查看网络：使用docker network ls命令查看所有Docker网络。
   * 创建网络：使用docker network create命令创建自定义网络。
   * 连接容器到网络：在创建或运行容器时指定网络。
6. Docker Compose：
   * 编写Dockerfile：用于自动化构建Docker镜像。
   * 编写docker-compose.yml：定义多容器应用的服务、网络和卷。
   * 使用docker-compose命令：如docker-compose up来启动整个应用。
7. Docker可视化工具：可以使用如Docker Desktop、Portainer等可视化工具来更方便地管理Docker容器和镜像。

# linux内核
Linux内核是Linux操作系统的核心部分，它负责管理系统的硬件和软件资源，确保系统的正常运行。Linux内核的主要功能包括进程管理、内存管理、文件系统、设备驱动和网络系统等。

Linux内核采用单内核模式，将所有基本功能集于同个进程，形成一个大进程。内核内部采用的是模块化设计，不同功能属于不同模块，模块间通信采用的是函数调用。运行内核的所有信息都在内核空间，而用户程序普遍都在用户空间。若用户程序想使用内核功能时，则需通过内核提供的接口，进行系统调用。


# 数据库分库分表，啥时候分库啥时候分表
1. 数据量巨大：当单表的数据量达到百万、千万甚至亿级别时，查询效率会明显下降，这时可以考虑进行分表。通过将数据分散到多个表中，可以减少单个表的负担，提高查询性能。
2. 访问频率高：如果某个表的访问频率非常高，导致数据库连接成为瓶颈，也可以考虑分表。通过将数据分散到多个表中，可以分散数据库的访问压力，提高系统的并发处理能力。
3. 业务复杂度提高：随着业务的发展，可能需要将不同的业务数据存储在不同的数据库中，以实现业务的隔离和管理。这时可以考虑进行分库，将不同业务的数据分散到不同的数据库中。
4. 硬件资源限制：当单台服务器的硬件资源（如CPU、内存、磁盘空间等）无法满足数据存储和处理的需求时，也可以考虑分库分表。通过将数据分散到多台服务器上，可以充分利用硬件资源，提高系统的整体性能


# 数据库的存储引擎有哪些，区别是啥
1. InnoDB：InnoDB是MySQL的默认存储引擎，它支持事务处理、行级锁定和外键约束。InnoDB的设计目标是提供高性能和可靠性，同时支持ACID事务特性。它使用多版本并发控制（MVCC）来提高并发性能，并且具有崩溃恢复能力。
2. MyISAM：MyISAM是MySQL的另一个常见的存储引擎，它主要适用于读密集型的应用。MyISAM不支持事务处理和外键约束，但它提供了全文索引和高速缓存功能。MyISAM在处理非事务性的工作负载时通常比InnoDB更快。
3. Memory（或HEAP）：Memory存储引擎将所有数据存储在RAM中，因此它提供了极快的读写性能。但是，由于数据存储在内存中，如果数据库服务器崩溃或重启，数据将丢失。Memory存储引擎适用于临时表、缓存和需要快速访问的数据。
4. Archive：Archive存储引擎是MySQL中用于存储和检索大量归档数据的引擎。它使用gzip算法对数据进行压缩，以节省存储空间。Archive表只支持INSERT和SELECT操作，不支持UPDATE和DELETE操作。它适用于存储历史数据、日志等不需要频繁更新的数据

# innodb索引用的是啥，为什么不用b树、红黑
InnoDB存储引擎在MySQL中使用的索引结构主要是B+树（B+ Tree）。虽然红黑树（Red-Black Tree）等其他数据结构也可以用于实现索引，但B+树更适合数据库索引的场景，原因如下：

1. 磁盘I/O操作：数据库索引的主要目的是提高查询性能，而查询性能的一个关键因素就是减少磁盘I/O操作。B+树的设计非常适合磁盘I/O操作，因为它能够保持树的平衡，使得查找、插入和删除操作的磁盘I/O次数相对较少。相比之下，红黑树等平衡二叉树在磁盘上的性能较差，因为它们可能导致树的高度较高，从而增加磁盘I/O次数。
2. 范围查询：B+树的所有叶子节点都通过指针相连，这使得范围查询（例如查询某个范围内的所有记录）变得非常高效。InnoDB利用这一特性，可以高效地执行范围查询。而红黑树等数据结构则不具备这种特性。
3. 数据排序：由于B+树的叶子节点是有序的，因此在某些情况下，InnoDB可以利用索引进行排序操作，进一步减少磁盘I/O次数。
4. 索引大小：B+树的非叶子节点仅存储键值信息，不存储数据，这使得索引本身的大小相对较小，从而减少了磁盘空间的占用。
综上所述，B+树作为InnoDB存储引擎的索引结构，能够更好地满足数据库查询性能的需求，因此在数据库系统中得到了广泛应用。

# 事务的隔离级别
事务的隔离级别是数据库管理系统（DBMS）中用于控制多个并发事务之间可见性和相互影响程度的设置。这些隔离级别定义了事务在访问和修改数据时所能看到的数据状态，以及它们对其他并发事务的影响

1. 读未提交（Read Uncommitted）：这是最低的隔离级别。在这个级别下，一个事务可以读取另一个尚未提交的事务的数据。这可能导致“脏读”问题，即读取到其他事务尚未提交的数据，这些数据可能最终会被回滚，从而导致读取到的数据不准确。
2. 读已提交（Read Committed）：这是大多数数据库的默认隔离级别，如Oracle和Sqlserver。在这个级别下，一个事务只能看到其他事务已经提交的更新。这消除了“脏读”问题，因为一个事务不会读取到另一个事务尚未提交的数据。但是，它仍然可能面临“不可重复读”和“幻读”问题。
3. 可重复读（Repeatable Read）：这是MySQL数据库的默认隔离级别。在这个级别下，一个事务在进行多次同样的数据内容查询时，得到的结果是一样的，只要存在读改行数据就禁止写。这消除了“不可重复读”问题，因为在一个事务的执行过程中，多次读取同一数据会返回相同的结果。但是，它仍然可能面临“幻读”问题。
4. 串行化（Serializable）：这是事务隔离的最高级别，也是最安全最省心的级别。在这个级别下，一个事务在执行时会完全锁定相关的数据资源，禁止其他事务并发执行。这消除了“幻读”问题，因为所有并发事务都被串行化执行。但是，这种级别的隔离会导致并发性能降低，因为事务需要等待其他事务完成才能执行。

# 层序遍历二叉树
层序遍历二叉树是一种常用的遍历方法，也称为广度优先遍历（Breadth-First Search, BFS）。在层序遍历中，我们先访问根节点，然后逐层向下访问子节点，同一层的节点按照从左到右的顺序访问。


# 判断二叉树是否是镜像二叉树
方法一：将其中一颗二叉树转为镜像，并与另外一棵树进行比较判断各节点值是否相等。这种方法需要理解二叉树的镜像概念，即将二叉树的左右子树交换位置。

方法二：互为镜像的两个二叉树，每层数据顺序相反，逐层判断即可，需要注意结点为空的情况。这种方法需要逐层遍历二叉树，并比较每层节点的值是否对称。

方法三：递归实现——树1左结点和树2右结点判断；树1右结点和树2左结点判断。这种方法需要理解递归的概念，并通过递归函数来实现二叉树的镜像判断

# 堆排
堆排序（Heap Sort）是一种基于二叉堆（Binary Heap）的排序算法。它的基本思想是将待排序的序列构造成一个大顶堆（或小顶堆），此时，整个序列的最大值（或最小值）就是堆顶的根节点。然后将其与末尾元素进行交换，此时末尾就为最大值（或最小值）。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了。
堆排序可以分为两个主要步骤：
1. 建堆：将待排序的序列构造成一个大顶堆（或小顶堆）。这个过程从最后一个非叶子节点开始（对于长度为n的数组，最后一个非叶子节点的索引是 n/2 - 1），从右至左、从下至上进行调整。
2. 排序：将堆顶元素（最大或最小）与末尾元素交换，使末尾元素最大（或最小）。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次大值（或次小值）。如此反复执行，便能得到一个有序序列。

# 中间件:kafka丢失消息和不重复消费skip
# 对一个链表进行排序
要对链表进行排序，你可以使用多种算法，包括归并排序、插入排序和快速排序等



# 线程和协程的区别
1. 调度方式：线程由操作系统内核进行调度，而协程由程序员或运行时环境进行调度。线程的调度是由操作系统决定的，它可以在不同的核心上并行执行。而协程的调度是由程序员显式地控制的，它在单个线程内通过协作式调度来实现并发。
2. 并发性：线程是并发执行的，多个线程可以同时执行不同的任务。而协程是协作式的，只有一个协程在执行，其他协程需要等待当前协程主动释放控制权才能执行。
3. 资源占用：线程需要独立的堆栈空间，每个线程都有自己的堆栈，因此线程的内存消耗较大。而协程共享线程的堆栈，因此协程的内存消耗较小。
4. 切换开销：线程的切换需要保存和恢复线程的上下文，这涉及到内核态和用户态之间的切换，开销较大。而协程的切换只需要保存和恢复协程的上下文，开销较小。
5. 错误处理：线程的错误处理相对复杂，需要使用锁和同步机制来保护共享资源。而协程的错误处理相对简单，可以使用异常处理机制来处理错误。
6. 优先级：线程没有优先级，它们的调度完全由操作系统决定。而协程可以有优先级，程序员可以根据需要设置协程的优先级，从而控制协程的执行顺序。
7. 调度速度：协程的调度速度几乎比线程快一个数量级，因为协程的调度由编程者控制，可以减少无效的调度。
8. 创建数量：由于协程的调度损耗较小，因此真实可创建且有效的协程数量可以比线程多很多。然而，由于调度和资源的限制，有效协程的数量也是有上限的。

协程是用户态的线程

# TCP三次握手和四次挥手
长连接和短链接(怎么实现的、区别以及应用场景)
计算二叉树所有左叶子节点的和
n对括号输出所有合法的情况
n个有序的数组合并成一个
协程和线程的区别，内核态和用户态
btree和b+tree
二叉树中序遍历，递归和非递归两种方式
kafka如何保证消息有序，消息的重复和丢失
http和https的区别，https建立连接的过程
http1.1和http2.0的区别
缓存和数据库一致性的问题
syncpool的实现原理
hash冲突解决办法，有什么弊端
map里面解决hash冲突怎么做的，冲突了元素放在头还是尾
10亿的url去重怎么做
rediszset怎么使用的，底层怎么实现的，适用于什么场景
单链表找到中间节点
设计一个秒杀系统
给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针
while(tree){sleep(1)}这个会有什么问题
sleep底层实现原理
线上问题一般怎么排查，比如oom
手写LRU相关知识点：模拟，结构，增删改查
一个整型数组，数组中的一个或连续多个整数组成一个子数组。求所有子数组的和的最大值
docker和虚拟机区别
k8s底层原理
linux文件系统
网络七层模型和五层模型
数据库索引
MySQL优化（索引、分表分库）
最左匹配原则？问为什么有这个东西？
同一个协程里面，对无缓冲channel同时发送和接收数据有什么问题
channel和锁对比一下
channel的应用场景
slice和array区别
向为nil的channel发送数据会怎么样
map取一个key，然后修改这个值，原map数据的值会不会变化
Hash实现、冲突解决、应用
输入URL发生的整个网络过程
Redis怎么保证数据一致性
TCP流量控制、拥塞控制
TCP半连接队列
TCP半关闭状态
TCPTIME_WAIT状态
内核态、用户态
100枚硬币，其中有一枚硬币重量不一样，用天平秤怎么快速找到这一枚硬币
LRU缓存实现，要求set\get操作o(1)时间复杂度
TCP滑动窗口
一个SQL语句的执行过程
MVCC原理
ACID的涵义，MYSQL是如何保证的
缓存失效的几种场景，以及解决方案
缓存雪崩、击穿的解决方案
如何排查线上程序问题
protobuf为什么快
分布式系统优缺点，一致性是如何保证的
雪崩、穿透和击穿
最终一致性
mysql分布式id
mysql索引慢分析：线上开启slowlog，提取慢查询，然后仔细分析explain中tye字段以及extra字段，发生的具体场景及mysql是怎么做的
mysql分库分表平滑扩容方案
docker预热
gowaitgroup的坑
k8s原理
mysql隔离级别、sql慢查询
etcd原理
给一个栈，用另外一个栈实现排序
gostruct能不能比较
select可以用于什么
context包的用途
client如何实现长连接
主协程如何等其余协程完再操作
slice，len，cap，共享，扩容
map如何顺序读取
大文件排序
数据库如何建索引
tcp与udp区别，udp优点，适用场景
raft算法是那种一致性算法
一个请求到达pod的过程、configmap、dockerfile
二叉树遍历，非递归