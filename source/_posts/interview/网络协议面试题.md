---
title: 网络协议面试题
categories: 
- interview
tags:
- 面试题
---


# 从URL在浏览器输入到页面展现的过程中发生了什么
1. DNS解析：首先，浏览器会解析输入的URL，将其中的域名转换为对应的IP地址。这个过程涉及到DNS（Domain Name System）解析。浏览器首先会查看本地缓存中是否有该域名的IP地址记录，如果有则直接使用。如果没有，浏览器会向DNS服务器发送查询请求。DNS服务器会递归查询域名，最终找到对应的IP地址并返回给浏览器。
2. 建立TCP连接：拿到服务器的IP地址后，浏览器会与服务器建立TCP（Transmission Control Protocol）连接。这个过程包括三次握手：
    * 客户端发送SYN（同步）报文，并置发送序号为X。
    * 服务端回复SYN+ACK（同步/应答）报文，并置发送序号为Y，再确认序号为X+1。
    * 客户端发送ACK（应答）报文，并置发送序号为Z，再确认序号为Y+1。这样，TCP连接就建立起来了。
3. 发送HTTP请求：建立TCP连接后，浏览器会向服务器发送HTTP请求。HTTP请求报文包括了请求方法（如GET、POST等）、请求路径、协议版本以及请求头部信息等。这些信息封装在TCP报文段中发送给服务器。
4. 服务器处理HTTP请求：服务器接收到HTTP请求后，会根据请求路径和方法来定位并处理相应的资源。这可能涉及到文件读取、数据库查询等操作。处理完成后，服务器会生成HTTP响应报文，其中包括状态码、响应头部信息以及响应体等。
5. 返回HTTP响应：服务器将HTTP响应报文通过之前建立的TCP连接发送回浏览器。浏览器接收到响应报文后，会解析HTTP响应，提取出状态码、响应头部以及响应体等信息。
6. 渲染页面：浏览器根据解析得到的HTML文档构建DOM（Document Object Model）树，并下载并解析CSS样式表、JavaScript脚本等资源。然后，浏览器会进行页面渲染，将HTML、CSS和JavaScript等组合起来生成最终的页面展示给用户。
7. 关闭TCP连接：当浏览器从服务器接收到所有需要的数据后，会关闭TCP连接。这个过程包括四次挥手：
    * 客户端发送FIN（结束）报文，通知服务器要关闭连接。
    * 服务器回复ACK报文，确认收到关闭连接的请求。
    * 服务器发送FIN报文，通知客户端已经关闭连接。
    * 客户端回复ACK报文，确认收到服务器关闭连接的通知。这样，TCP连接就被关闭了。

<!--more-->


# HTTP1.1/HTTP2/HTTP3 的区别
HTTP1.1:   
1. 支持了长连接
2. 串行请求带来的队头阻塞的问题
3. Pipelining技术可以在一个tcp上发送多个请求，但响应还是依次回来的


HTTP2:  
1. 引入二进制分帧，实现多路复用，解决http协议层面的队头阻塞问题，但TCP层面的队头阻塞问题，依然存在
2. 支持头部压缩
3. 支持服务器主动推送


HTTP3:  
1. QUIC协议，基于UDP


> 一个浏览器针对每一个域名最大可以建立6个TCP连接
# 简述HTTP2.0多路复用

每个请求都被视为一个独立的流，每个流都有一个唯一的标识符,因此服务器无须再顺序返回请求。

# HTTP协议和RPC协议有什么区别
1. 基于的通信协议：HTTP协议主要基于HTTP，而RPC（远程过程调用）协议则更为灵活，可以基于HTTP、TCP和UDP等协议。
2. 调用方式：HTTP接口通过URL进行调用，而RPC接口则通过函数调用进行调用。这意味着RPC在调用时具有更直接的特性。
3. 使用场景：HTTP协议主要用于B/S架构，特别是在Web浏览器和服务器之间的数据通信中。而RPC则更多地用于C/S架构，如分布式系统内部集群，如云计算、微服务架构、分布式数据库等，以实现不同服务之间的远程调用和分布式系统协作。
4. 传输效率：RPC使用自定义的TCP协议，使得请求报文体积更小，从而提高了传输效率。而HTTP协议，尤其是基于HTTP1.1的协议，请求中会包含很多无用的内容，从而降低了传输效率。
5. 性能与效率：RPC协议通常使用二进制编码来传输数据，相对于HTTP协议的文本传输，RPC具有更高的性能和效率。此外，RPC协议还常采用高效的序列化和反序列化技术，进一步减少了数据传输的大小和开销，提高了通信的速度和响应时间。
6. 安全性：由于RPC常用于内部系统间的通信，通常在内部网络环境下进行，因此其安全性相对更高。

# 简述HTTPS加密过程
HTTPS的加密过程实际上是一个混合加密过程，涉及建立连接前的连接阶段和建立连接后的通信阶段  
1. 客户端发起HTTPS请求：首先，客户端（通常是浏览器）向服务器发送一个HTTPS请求。这个请求中包含了客户端支持的加密算法种类、SSL/TLS协议版本号以及一个随机数等信息。
2. 服务器的响应：服务器收到请求后，会向客户端回传SSL/TLS协议版本号、选择的加密算法和HASH算法、服务器的证书（包含了网站的地址、加密公钥以及证书的颁发机构等信息）以及一个随机数。
3. 客户端验证服务器的合法性：客户端利用收到的服务器证书中的信息验证服务器的合法性。验证包括检查证书是否过期、发行证书的CA是否可靠、证书的公钥能否正确解开证书的数字签名以及证书上的域名是否与实际的服务器域名匹配等。如果验证通过，则继续通信，否则断开连接。
4. 生成对称加密密钥：在验证服务器合法性后，客户端会生成一个随机数作为对称加密的密钥。
5. 密钥的加密传输：客户端使用服务器证书中的公钥对这个对称加密密钥进行加密，得到加密后的密钥。
6. 加密密钥的传输与解密：客户端将加密后的密钥发送给服务器。服务器使用自己的私钥对接收到的加密密钥进行解密，得到对称加密的密钥。
7. 使用对称加密密钥进行通信：至此，客户端和服务器之间共享了一个对称加密密钥。之后的消息传递都会使用这个对称加密密钥进行加密和解密，确保通信内容的安全性。

在整个过程中，HTTPS采用了非对称加密和对称加密相结合的方式，既保证了数据传输的安全性，又提高了加密和解密的效率。同时，通过摘要算法和数字签名等技术，保证了数据的完整性和服务器的身份认证。

# TCP
面向**连接**，**可靠**的,基于字节流的传输层通信协议

# SOCKET
* 套接字
* 四元组  ip:port + ip:port
* 操作系统最多有65535个端口

一个客户端与服务器最多建立多少个TCP？   
由于客户端端口是65535个，所以客户端最多建立65535个连接 ，服务端只监听了一个端口，服务端可以建立无数个，取决于硬件资源（内存）

一个客户端已经和服务器建立建立的情况下，是否可以和这个服务器的其它端口建立连接（端口是否可以重用）？  
可以，四元组的唯一性

既然一个客户端和服务器最多建立65535个连接，那如果想实现十万/百万连接如何处理？    
增加ip地址，一个网卡可以增加多个ip地址，（还是四元组的唯一性）

# TCP面向连接的，怎么理解这个连接
连接本质的数据结构，资源的开辟

TCP 建立连接的本质是在客户端和服务端各自维护一定的数据结构（一种状态机），来记录和维护这个“连接”的状态

发送数据之前，双方需要先进行一系列的握手操作，以初始化并建立连接状态。这个过程被称为三次握手。

# TCP是可靠的，怎么理解这个可靠
1. **数据完整性**：TCP协议通过校验、序号、确认和重传等机制确保数据的完整性。每个TCP报文段都包含校验和，用于检查数据在传输过程中是否发生了错误。同时，每个报文段都有一个序号，接收方会按照序号顺序接收数据，确保数据的顺序性。如果接收方发现数据有误或丢失，会要求发送方重新发送，这就是重传机制。
2. **面向连接**：TCP是面向连接的协议，这意味着在通信开始之前，必须建立连接。这种连接状态确保了通信的可靠性，因为只有在连接建立成功后，数据才会开始传输。这种连接状态还使得发送方和接收方都可以确认对方的存在和接收能力，从而进一步增强了通信的可靠性。
3. **确认应答机制**：TCP使用确认应答机制来确保数据的可靠传输。当接收方收到数据后，它会向发送方发送一个确认报文，告知发送方数据已成功接收。如果发送方在一段时间内未收到确认报文，它会认为数据丢失并重新发送数据。
4. **流量控制和拥塞控制**：TCP还使用流量控制和拥塞控制机制来确保数据的可靠传输。流量控制允许接收方控制发送方的发送速率，以防止接收方缓冲区溢出。拥塞控制则用于避免网络拥塞，当网络出现拥塞时，TCP会降低发送速率，以减轻网络负担。


# 三次握手
1. A > SYN  > B  请求建立连接
2. A < SYN+ACK < B  告诉客户端可以创建
3. A > ACK > B 客户端创建完成，响应给ACK给服务端，完成连接建立

# 四次挥手
客户端和服务端断开连接（释放资源）
1. A > FIN > B
2. A < FIN+ ACK < B  收到断开请求，做清理工作
3. A < FIN < B 服务端做完清理工作，确认断开
4. A > ACK > B 客户端处理完清理工作，确认断开

# TCP流量控制
TCP流量控制的主要目的是确保发送方的发送速率不会过快，以便接收方能够来得及接收数据，从而避免数据的丢失。

TCP流量控制通过滑动窗口机制来实现。在建立连接时，发送的报文段中会包含接收窗口的单位值。发送方的窗口大小不能超过接收方给出的接收窗口的数值。滑动窗
口的大小是动态调整的，每一次接收方回复给发送方的确认报文段里会更新新的接收窗口值。当接收窗口为0时，代表暂时不接收数据，直到接收方重新给发送方发出一个新的窗口值为止。


# TCP拥塞控制

当网络中的某一资源（如带宽、交换机中的缓存和处理机等）的需求超过其所能提供的可用部分时，网络的性能会变差，这种现象称为拥塞。TCP拥塞控制的目的就是防止这种情况的发生。


TCP主要使用四个算法来进行拥塞控制：慢开始、拥塞避免、快重传和快恢复。  
1. 慢开始：在建立连接和开始发送数据时，发送方会先发送少量的数据，并观察网络的反馈。如果网络状况良好，没有出现丢包或超时，那么发送方会逐渐增加发送窗口的大小，即逐步增加发送数据的速率。
2. 拥塞避免： 当网络资源接近其容量限制时，拥塞避免算法会主动调整发送方的发送速率，以防止网络拥塞的发生。
3. 快重传算法：是针对丢包情况的一种优化策略。当接收方收到一个失序的报文段时，它会立即发送一个重复确认，告诉发送方哪些报文段已经收到，哪些还没有收到。如果发送方连续收到三个或更多的重复确认，那么它会认为某个报文段已经丢失，并立即重传那个报文段，而不是等待超时定时器超时后再重传。
4. 快恢复：快恢复算法是与快重传算法配合使用的。当发送方收到三个或更多的重复确认时，它会认为网络只是出现了暂时的拥塞，而不是出现了严重的拥塞。因此，发送方不会立即将拥塞窗口cwnd减小到最小值，而是将其减半，并执行拥塞避免算法。这样可以更快地恢复数据的传输速率，同时避免网络拥塞的进一步加剧。


# rpc微服务框架
## 微服务之间如何进行通信？
* 单体项目时：一次服务调用发生在同一台机器上的同一个进程内部，也就是说调用发生在本机内部，因此也被叫作本地方法调用。
* 微服务项目时：服务提供者和服务消费者运行在两台不同物理机上的不同进程内，它们之间的调用相比于本地方法调用，可称之为远程方法调用，简称 RPC

## RPC了解多少？都有哪些？
* GRPC：Google 2015 年开源，支持多种语言
* Thrift：最初Facebook 开发的内部框架，2007 年贡献给了 Apache 基金，成为 Apache 开源项目之一，支持多种语言。
* RPCX

## RPC包含哪些部分？
* 客户端和服务端建立网络连接模块( server模块、client模块 )
* 服务端处理请求模块
* 协议模块
* 序列化和反序列模块

## 设计一个RPC会考虑哪些问题?
* 客户端和服务端如何建立网络连接？
* 服务端如何处理请求？
* 数据传输采用什么协议？
* 数据该如何序列化和反序列化？

## 服务端如何处理请求？有哪些方式？
服务端接收到客户端的请求后，常见的处理方式有三种，分别是BIO、NIO和AIO。
* **同步阻塞方式（BIO）** 客户端发一次请求，服务端生成一个对应线程去处理。当客户端同时发起的请求很多时，服务端需要创建多个线程去处理每一个请求，当达到了系统最大的线程数时，新来的请求就无法处理了。
* **同步非阻塞方式 (NIO)**  客户端发一次请求，服务端并不是每次都创建一个新线程来处理，而是通过 I/O 多路复用技术进行处理。就是把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求。这种方式的优势是开销小，不用为每个请求创建一个线程，可以节省系统开销。
* **异步非阻塞方式（AIO）**  客户端发起一个 I/O 操作然后立即返回，等 I/O 操作真正完成以后，客户端会得到 I/O 操作完成的通知，此时客户端只需要对数据进行处理就好了，不需要进行实际的 I/O 读写操作，因为真正的 I/O 读取或者写入操作已经由内核完成了。这种方式的优势是客户端无需等待，不存在阻塞等待问题。

> BIO 适用于连接数比较小的业务场景，这样的话不至于系统中没有可用线程去处理请求。这种方式写的程序也比较简单直观，易于理解。
> NIO 适用于连接数比较多并且请求消耗比较轻的业务场景，比如聊天服务器。这种方式相比 BIO，相对来说编程比较复杂。
> AIO 适用于连接数比较多而且请求消耗比较重的业务场景，比如涉及 I/O 操作的相册服务器。这种方式相比另外两种，编程难度最大，程序也不易于理解。 【来自网络】

## IO多路复用
多个的进程的IO可以注册到一个复用器（select）上，然后用一个进程调用该select， select会监听所有注册进来的IO；  
如果select没有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞；而当任一IO在内核缓冲区中有可数据时，select调用就会返回；  
而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据。  
多个进程注册IO后，只有另一个select调用进程被阻塞。

IO多路复用实现有三种方案：select、poll、epoll

### select
select 的fd_set通过bitmap 1024位的方式存储fd  
bitmap从用户态拷贝到内核态，由内核态来判断，没有数据变化，select会阻塞，有变化，bitmap的fd会被置位

缺点：
1. 1024的大小限制
2. fdset不可重用
3. rset(bitmap) 用户态到内核态的开销
4. 复杂度为O(n)

### poll
poll将要监听的对象存到数组中，且数组中的元素是结构体
```
struct pollfd
{
    int fd;
    short events;//事件
    short revents;//有变化被置位，什么事件，置为什么事件，最后要将revents重新置为0
}

```
解决了select中 的两个问题
1. 1024的大小限制
2. fdset不可重用

### epoll

在epoll机制中，Linux内核会创建一个eventpoll结构体，其中包含了红黑树和双向链表两种数据结构。红黑树用于fd，而双向链表则用于存储就绪的fd。

当程序调用epoll_create函数时，会创建一个epoll对象，并返回一个文件描述符。然后，程序可以通过epoll_ctl函数向epoll对象中添加或删除需要监听的套接字。这些套接字会与设备驱动程序建立回调关系，一旦有事件发生（如数据可读、可写等），就会调用内核中的回调函数，将事件添加到双向链表中。

当程序需要收集发生的事件时，可以调用epoll_wait函数。该函数会检查eventpoll对象中的双向链表，如果链表不为空，则将发生的事件复制到用户空间，并清空链表。同时，epoll_wait函数还会返回事件的数量。

epoll机制有两种工作模式：水平触发和边缘触发。在水平触发模式下，只要文件描述符处于就绪状态，epoll就会持续通知应用程序进行I/O操作。而在边缘触发模式下，只有在文件描述符从未就绪状态转换为就绪状态时，epoll才会通知应用程序进行I/O操作。通常情况下，推荐使用边缘触发模式，因为它能更高效地利用CPU资源

#### 监视socket索引-红黑树
为什么采用红黑树呢？因为和epoll的工作机制有关。epoll在添加一个socket或者删除一个socket或者修改一个socket的时候，它需要查询速度更快，操作效率最高，因此需要一个更加优秀的数据结构能够管理这些socket。

我们想到的比如链表，数组，二叉搜索树，B+树等都无法满足要求:
* 因为链表在查询，删除的时候毫无疑问时间复杂度是O(n)；
* 数组查询很快，但是删除和新增时间复杂度是O(n)；
* 二叉搜索树虽然查询效率是lgn，但是如果不是平衡的，那么就会退化为线性查找，复杂度直接来到O(n)；
* B+树是平衡多路查找树，主要是通过降低树的高度来存储上亿级别的数据，但是它的应用场景是内存放不下的时候能够用最少的IO访问次数从磁盘获取数据。

因为我们处理上万级的fd，它们本身的存储空间并不会很大，所以倾向于在内存中去实现管理，而红黑树是一种非常优秀的平衡树，它完全是在内存中操作，而且查找，删除和新增时间复杂度都是lgn，效率非常高，因此选择用红黑树实现epoll是最佳的选择。

当然不选择用AVL树是因为红黑树是不符合AVL树的平衡条件的，红黑是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决；而AVL树是严格平衡树，在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高。

#### 就绪socket列表-双向链表
就绪列表存储的是就绪的socket，所以它应能够快速的插入数据。

程序可能随时调用epoll_ctl添加监视socket，也可能随时删除。当删除时，若该socket已经存放在就绪列表中，它也应该被移除。（事实上，每个epoll_item既是红黑树节点，也是链表节点，删除红黑树节点，自然删除了链表节点）

所以就绪列表应是一种能够快速插入和删除的数据结构。双向链表就是这样一种数据结构，epoll使用双向链表来实现就绪队列（rdllist）


#### epoll为什么比select/poll快，快在什么地方
1. epoll只是在调用epoll_ctl的时候才会把fd从用户态拷贝的内核态，而select/poll每次执行的时候都会把fd全部拷贝到内核态
2. 调用epoll_wait时候，只会拷贝已就绪的事件到用户态
3. epoll采用事件回调机制，将已就绪的fd加入到链表中，而不是像select/poll主动轮询的方式获取就绪事件

